# NuboBackend
## âœ… Objectif final

Un backend nommÃ© `nubo-backend` avec :

- API REST (auth, CRUD de posts/messages, etc.)
- WebSocket (temps rÃ©el)
- Redis (cache/session)
- PostgreSQL (stockage permanent)
- MongoDB (stockage temporaire 30 jours)
- Docker (zÃ©ro installation locale, sauf Docker)

---

## ğŸ§± PRÃ‰REQUIS (macOS)

Avant tout, installe :

- [Docker Desktop pour Mac](https://www.docker.com/products/docker-desktop/)
  - Ouvre-le une fois installÃ©
- Go (Golang) *(facultatif si tu build tout dans Docker, mais conseillÃ© pour dev local)*  
  `brew install go`
- Git *(souvent dÃ©jÃ  prÃ©sent)*  
  `git --version`
- (Optionnel) Un bon Ã©diteur :
  - [VS Code](https://code.visualstudio.com/)
    - Extensions recommandÃ©es : **Go**, **Docker**, **GitLens**

---

## ğŸ—‚ï¸ STRUCTURE DU PROJET

```
nubo-backend/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .env
â”œâ”€â”€ go.mod
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ main.go
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ api/         â† Handlers REST
â”‚   â”œâ”€â”€ websocket/   â† Serveur WebSocket
â”‚   â”œâ”€â”€ db/          â† Connexion PostgreSQL & Mongo
â”‚   â”œâ”€â”€ cache/       â† Connexion Redis
â”‚   â””â”€â”€ models/      â† Structs & logique mÃ©tier
â””â”€â”€ README.md
```

---

## I. ğŸ”¨ Ã‰TAPES DE DÃ‰VELOPPEMENT GO/DOCKER

### 1. Initialiser ton projet Go

```bash
mkdir nubo-backend && cd nubo-backend
go mod init github.com/tonuser/nubo-backend
```

> Remplace `tonuser` par ton pseudo GitHub

---

### 2. CrÃ©er les fichiers essentiels

```bash
touch Dockerfile docker-compose.yml .env README.md
mkdir -p cmd internal/{api,websocket,db,cache,models}
touch cmd/main.go
```

---

### 3. Ajouter les dÃ©pendances Go

Installe les libs de base avec :

```bash
go get github.com/gin-gonic/gin              # REST API
go get github.com/go-redis/redis/v8          # Redis
go get go.mongodb.org/mongo-driver/mongo     # MongoDB
go get github.com/jackc/pgx/v5               # PostgreSQL
go get github.com/gorilla/websocket          # WebSocket
```

---

### 4. Ã‰crire ton `main.go`

```go
package main

import (
	"github.com/gin-gonic/gin"
)

func main() {
	r := gin.Default()

	r.GET("/ping", func(c *gin.Context) {
		c.JSON(200, gin.H{"message": "pong"})
	})

	r.Run(":8080")
}
```

---

### 5. CrÃ©er le `Dockerfile`

```Dockerfile
FROM golang:1.24.5

WORKDIR /app

COPY go.mod ./
COPY go.sum ./
RUN go mod download

COPY . .

RUN go build -o nubo cmd/main.go

EXPOSE 8080

CMD ["./nubo"]
```

---

### 6. CrÃ©er le `docker-compose.yml`

```yaml
services:
  api:
    build: .
    container_name: nubo_api
    ports:
      - "8080:8080"
    env_file:
      - .env
    depends_on:
      - redis
      - postgres
      - mongo
    restart: always

  redis:
    image: redis:7
    container_name: nubo_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  postgres:
    image: postgres:15
    container_name: nubo_postgres
    environment:
      POSTGRES_USER: nubo
      POSTGRES_PASSWORD: nubo
      POSTGRES_DB: nubo
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  mongo:
    image: mongo:7
    container_name: nubo_mongo
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

volumes:
  redis_data:
  postgres_data:
  mongo_data:
```

---

### 7. Lancer ton environnement

```bash
docker-compose up --build
```

Puis va sur [http://localhost:8080/ping](http://localhost:8080/ping) â†’ tu dois voir :

```json
{ "message": "pong" }
```

---

## II. ğŸŒ CrÃ©ation du repo GitHub

- CrÃ©er un repo vide (sur github.com) :
- Nom : nubo-backend
- VisibilitÃ© : PrivÃ© ou Public, Ã  toi de voir
- Puis en terminal :
```bash
git init
git remote add origin https://github.com/TON_USER/nubo-backend.git
git add .
git commit -m "Initial commit"
git branch -M main
git push -u origin main
```

---

## III. ğŸ› ï¸ Plan dâ€™action clair (prochaine phase go)

âœ… Ã‰tape 1 â€” Ajouter les routes REST : Login, Signup, Post
âœ… Ã‰tape 2 â€” Ajouter le WebSocket en Go
âœ… Ã‰tape 3 â€” Brancher PostgreSQL, MongoDB, Redis
âœ… Ã‰tape 4 â€” Ajouter lâ€™authentification JWT
âœ… Ã‰tape 5 â€” DÃ©ployer sur un serveur Linux (Docker Compose + .env)
âœ… Ã‰TAPE 1 â€” CrÃ©er les routes REST de base

---

### ğŸ¯ Objectif
**CrÃ©er des routes :**

- `POST /signup` â†’ crÃ©er un utilisateur
- `POST /login` â†’ connecter (renvoyer JWT, Ã  faire en Ã‰tape 4)
- `GET /posts` â†’ rÃ©cupÃ©rer les posts
- `POST /posts` â†’ crÃ©er un post

### ğŸ“ Organisation recommandÃ©e
Fichier : `internal/api/routes.go`
```go
package api

import (
	"github.com/gin-gonic/gin"
	"net/http"
)

func SetupRoutes(r *gin.Engine) {
	r.POST("/signup", SignUpHandler)
	r.POST("/login", LoginHandler)

	r.GET("/posts", GetPostsHandler)
	r.POST("/posts", CreatePostHandler)
}

func SignUpHandler(c *gin.Context) {
	// TODO: lire JSON, enregistrer utilisateur
	c.JSON(http.StatusOK, gin.H{"message": "signup ok"})
}

func LoginHandler(c *gin.Context) {
	// TODO: vÃ©rifier identifiants, renvoyer JWT
	c.JSON(http.StatusOK, gin.H{"message": "login ok"})
}

func GetPostsHandler(c *gin.Context) {
	// TODO: rÃ©cupÃ©rer les posts depuis la base
	c.JSON(http.StatusOK, gin.H{"posts": []string{"post 1", "post 2"}})
}

func CreatePostHandler(c *gin.Context) {
	// TODO: ajouter post Ã  la base
	c.JSON(http.StatusCreated, gin.H{"message": "post created"})
}
```

Ensuite, dans `cmd/main.go` :
```go
package main

import (
	"github.com/gin-gonic/gin"
	"github.com/QuentinRegnier/nubo-backend/internal/api"
)

func main() {
	r := gin.Default()
	api.SetupRoutes(r)
	r.Run(":8080")
}
```

Tu peux tester les endpoints avec curl ou Postman :
```bash
curl -X POST http://localhost:8080/signup
```
â†’ tu dois voir :
```json
{"message":"signup ok"}
```

---

## IV. ğŸš€ Ã‰tape WebSocket : crÃ©er un serveur WebSocket basique en Go avec Gin + Gorilla WebSocket
### 1. CrÃ©er un handler WebSocket

Fichier : `internal/websocket/handler.go`
```go
package websocket

import (
	"net/http"
	"github.com/gin-gonic/gin"
	"github.com/gorilla/websocket"
	"log"
)

// Configure le Upgrader (permet de passer du HTTP au WS)
var upgrader = websocket.Upgrader{
	CheckOrigin: func(r *http.Request) bool {
		// TODO : en prod, tu peux vÃ©rifier l'origine ici
		return true
	},
}

func WSHandler(c *gin.Context) {
	conn, err := upgrader.Upgrade(c.Writer, c.Request, nil)
	if err != nil {
		log.Println("Erreur d'upgrade websocket:", err)
		return
	}
	defer conn.Close()

	log.Println("Client connectÃ© via WebSocket")

	for {
		// Lecture message du client
		_, msg, err := conn.ReadMessage()
		if err != nil {
			log.Println("Erreur lecture message:", err)
			break
		}

		log.Printf("Message reÃ§u: %s\n", msg)

		// Envoi dâ€™un message de retour (Ã©cho)
		err = conn.WriteMessage(websocket.TextMessage, []byte("Echo: "+string(msg)))
		if err != nil {
			log.Println("Erreur Ã©criture message:", err)
			break
		}
	}
}
```

---

### 2. Brancher le WebSocket dans Gin

Dans `internal/api/routes.go`, ajoute :
```go
package api

import (
	"github.com/gin-gonic/gin"
	"github.com/QuentinRegnier/nubo-backend/internal/websocket"
)

func SetupRoutes(r *gin.Engine) {
	// Routes REST...
	r.POST("/signup", SignUpHandler)
	r.POST("/login", LoginHandler)
	r.GET("/posts", GetPostsHandler)
	r.POST("/posts", CreatePostHandler)

	// WebSocket
	r.GET("/ws", websocket.WSHandler)
}
```

---

### 3. Tester ton WebSocket localement
```bash
websocat ws://localhost:8080/ws
```
Tape un message, tu dois recevoir un `Echo: ton_message`.

---

### 4. Ã‰tapes suivantes recommandÃ©es aprÃ¨s ce test

- Ajouter un gestionnaire de connexions multiples (pool clients broadcast)
- IntÃ©grer Redis Pub/Sub pour scaler (via un canal central)
- Connecter le WebSocket Ã  la base (exemple : notifications)
- ProtÃ©ger le WS avec JWT (authentification)
- GÃ©rer la reconnexion automatique cÃ´tÃ© client

---

### 5. Gestionnaire de connexions multiples + broadcast
### Objectif

Garder en mÃ©moire tous les clients connectÃ©s, pouvoir diffuser un message Ã  tous en mÃªme temps (broadcast).

### 6. Code Ã  ajouter `internal/websocket/hub.go`
```go
package websocket

import (
	"log"
	"sync"

	"github.com/gorilla/websocket"
)

type Client struct {
	conn *websocket.Conn
	send chan []byte
}

type Hub struct {
	clients    map[*Client]bool
	broadcast  chan []byte
	register   chan *Client
	unregister chan *Client
	mu         sync.Mutex
}

func NewHub() *Hub {
	return &Hub{
		clients:    make(map[*Client]bool),
		broadcast:  make(chan []byte),
		register:   make(chan *Client),
		unregister: make(chan *Client),
	}
}

func (h *Hub) Run() {
	for {
		select {
		case client := <-h.register:
			h.mu.Lock()
			h.clients[client] = true
			h.mu.Unlock()
			log.Println("Client registered")

		case client := <-h.unregister:
			h.mu.Lock()
			if _, ok := h.clients[client]; ok {
				delete(h.clients, client)
				close(client.send)
				log.Println("Client unregistered")
			}
			h.mu.Unlock()

		case message := <-h.broadcast:
			h.mu.Lock()
			for client := range h.clients {
				select {
				case client.send <- message:
				default:
					close(client.send)
					delete(h.clients, client)
				}
			}
			h.mu.Unlock()
		}
	}
}

func (c *Client) ReadPump(hub *Hub) {
	defer func() {
		hub.unregister <- c
		c.conn.Close()
	}()
	for {
		_, msg, err := c.conn.ReadMessage()
		if err != nil {
			log.Println("Read error:", err)
			break
		}
		// On envoie le message reÃ§u Ã  tout le monde
		hub.broadcast <- msg
	}
}

func (c *Client) WritePump() {
	for msg := range c.send {
		err := c.conn.WriteMessage(websocket.TextMessage, msg)
		if err != nil {
			log.Println("Write error:", err)
			break
		}
	}
	c.conn.Close()
}
```

### 7. Modifier le handler WebSocket `internal/websocket/handler.go`
```go
package websocket

import (
	"github.com/gin-gonic/gin"
	"github.com/gorilla/websocket"
	"log"
	"net/http"
)

var upgrader = websocket.Upgrader{
	CheckOrigin: func(r *http.Request) bool { return true },
}

var hub = NewHub()

func InitHub() {
	go hub.Run()
}

func WSHandler(c *gin.Context) {
	conn, err := upgrader.Upgrade(c.Writer, c.Request, nil)
	if err != nil {
		log.Println("Upgrade error:", err)
		return
	}

	client := &Client{
		conn: conn,
		send: make(chan []byte, 256),
	}

	hub.register <- client

	go client.WritePump()
	client.ReadPump(hub)
}
```

### Initialiser le hub dans `cmd/main.go`
```go
package main

import (
	"github.com/gin-gonic/gin"
	"nubo-backend/internal/api"
	"nubo-backend/internal/websocket"
)

func main() {
	r := gin.Default()

	websocket.InitHub()

	api.SetupRoutes(r)

	r.Run(":8080")
}
```

### 8. Test :
- Lance lâ€™API
- Connecte plusieurs clients au /ws
- Envoie un message dâ€™un client â†’ Tous les clients reÃ§oivent le message

---

## V. IntÃ©gration Redis Pub/Sub

Pourquoi ?

Pour permettre Ã  plusieurs instances de ton backend (scalÃ©es horizontalement) de communiquer, diffuser les messages WS entre elles.

### 1. Ajouter Redis Pub/Sub dans le hub

Installer Redis client dÃ©jÃ  fait avec `go-redis/redis/v8`

### 2. Ajouter un fichier `internal/cache/redis.go`
```go
package cache

import (
	"context"
	"os"

	"github.com/go-redis/redis/v8"
)

var Ctx = context.Background()
var Rdb *redis.Client

func InitRedis() {
	Rdb = redis.NewClient(&redis.Options{
		Addr:     os.Getenv("REDIS_ADDR"), // exemple : "localhost:6379"
		Password: "",                      // pas de mot de passe par dÃ©faut
		DB:       0,
	})
}
```

### 3. Modifie `cmd/main.go` pour initialiser Redis
```go
package main

import (
	"github.com/gin-gonic/gin"
	"nubo-backend/internal/api"
	"nubo-backend/internal/cache"
	"nubo-backend/internal/websocket"
	"log"
	"os"
)

func main() {
	// Initialiser Redis
	cache.InitRedis()

	// Initialiser Hub WS (modifiÃ© pour Redis)
	websocket.InitHub()

	r := gin.Default()
	api.SetupRoutes(r)

	port := os.Getenv("PORT")
	if port == "" {
		port = "8080"
	}
	log.Printf("Server listening on %s", port)
	r.Run(":" + port)
}
```

### 4. Modifier le hub pour utiliser Redis Pub/Sub

Dans `internal/websocket/hub.go` :

Ajoute en haut :
```go
import (
    "context"
    "log"
    "sync"

    "github.com/go-redis/redis/v8"
    "github.com/gorilla/websocket"
    "github.com/QuentinRegnier/nubo-backend/internal/cache"
)
```
Ajoute dans Hub :
```go
pubsub *redis.PubSub
channel string
Dans NewHub() :

h := &Hub{
	clients:    make(map[*Client]bool),
	broadcast:  make(chan []byte),
	register:   make(chan *Client),
	unregister: make(chan *Client),
	channel:    "nubo-websocket",
}
h.pubsub = cache.Rdb.Subscribe(context.Background(), h.channel)
go h.listenPubSub()
return h
```
Ajoute cette mÃ©thode :
```go
func (h *Hub) listenPubSub() {
	ch := h.pubsub.Channel()
	for msg := range ch {
		h.mu.Lock()
		for client := range h.clients {
			select {
			case client.send <- []byte(msg.Payload):
			default:
				close(client.send)
				delete(h.clients, client)
			}
		}
		h.mu.Unlock()
	}
}
```
Modifie la boucle case message := <-h.broadcast dans Run() :
```go
case message := <-h.broadcast:
	// Publie sur Redis
	err := cache.Rdb.Publish(context.Background(), h.channel, message).Err()
	if err != nil {
		log.Println("Redis publish error:", err)
	}
```

---

## VI. Connecter le WebSocket Ã  la base (exemple notifications)

### 1. Exemple rapide

Dans Client.ReadPump(), Ã  chaque message reÃ§u, tu peux enregistrer ou traiter en DB.

### 2. Exemple dans `internal/websocket/hub.go` ReadPump :
```go
func (c *Client) ReadPump(hub *Hub) {
	defer func() {
		hub.unregister <- c
		c.conn.Close()
	}()
	for {
		_, msg, err := c.conn.ReadMessage()
		if err != nil {
			log.Println("Read error:", err)
			break
		}

		// TODO: sauvegarder msg en base (Postgres/Mongo)

		// Envoie le message aux autres clients
		hub.broadcast <- msg
	}
}
```

---

## VII. ProtÃ©ger le WS avec JWT

### 1. Ajouter middleware dâ€™authentification JWT
TÃ©lÃ©charger avant :
```bash
go get github.com/golang-jwt/jwt/v5
```

Dans `internal/api/middleware.go` :
```go
package api

import (
	"net/http"
	"strings"

	"github.com/gin-gonic/gin"
	"github.com/golang-jwt/jwt/v5"
)

var jwtSecret = []byte("ta-cle-secrete") // Ã  sÃ©curiser via .env

func JWTMiddleware() gin.HandlerFunc {
	return func(c *gin.Context) {
		authHeader := c.GetHeader("Authorization")
		if authHeader == "" {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Authorization header manquant"})
			return
		}

		tokenString := strings.TrimPrefix(authHeader, "Bearer ")
		token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) {
			return jwtSecret, nil
		})

		if err != nil || !token.Valid {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Token invalide"})
			return
		}

		claims, ok := token.Claims.(jwt.MapClaims)
		if !ok {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Claims invalides"})
			return
		}

		// Stocke lâ€™ID utilisateur dans le contexte
		c.Set("userID", claims["sub"])

		c.Next()
	}
}
```

### 2. ProtÃ©ger la route WebSocket

Dans `internal/api/routes.go` :
```go
r.GET("/ws", JWTMiddleware(), websocket.WSHandler)
```
Dans `internal/websocket/handler.go`, rÃ©cupÃ©rer lâ€™ID utilisateur (exemple)
```go
func WSHandler(c *gin.Context) {
	userID := c.GetString("userID")
	log.Println("Utilisateur connectÃ© (userID):", userID)

	// â€¦ reste inchangÃ©
}
```

---

### 3. âœ… PRÃ‰REQUIS AVANT DE TESTER

- Redis tourne bien (docker-compose up)
- Ton backend Go est lancÃ© (go run cmd/main.go)
Tu as un JWT valide (car le WS est protÃ©gÃ© maintenant) â€” on en gÃ©nÃ¨re un dans l'Ã©tape 1 ğŸ‘‡

---

### 4. ğŸ§ª GÃ©nÃ©rer un JWT de test

**Ajoute un petit endpoint temporaire dans internal/api/routes.go juste pour tester :**
```go
import "github.com/golang-jwt/jwt/v5"

func SetupRoutes(r *gin.Engine) {
	r.GET("/token", func(c *gin.Context) {
		token := jwt.NewWithClaims(jwt.SigningMethodHS256, jwt.MapClaims{
			"sub": "user123", // ID utilisateur
		})
		tokenString, _ := token.SignedString([]byte("ta-cle-secrete"))
		c.JSON(200, gin.H{"token": tokenString})
	})

	r.GET("/ws", JWTMiddleware(), websocket.WSHandler)
}
```

Lance ton API puis exÃ©cute :
```bash
curl http://localhost:8080/token
```
Tu obtiens une rÃ©ponse comme :
```json
{"token":"eyJhbGciOiJIUzI1NiIsInR5cCI6Ikp..."}
```

---

### 5. ğŸ§ª Se connecter avec websocat + JWT

**Copie le token et lance cette commande dans le terminal :**
```bash
websocat ws://localhost:8081/ws -H 'Authorization: Bearer Remplace TON_JWT_ICI'
```
Remplace TON_JWT_ICI par le vrai token.

**âœ… Tu dois voir dans les logs :**
```bash
Utilisateur connectÃ© (userID): user123
Client registered
```

---

### 6. ğŸ§ª Tester le broadcast

- Ouvre deux terminaux avec cette mÃªme commande websocat (et le mÃªme token).
- Tape un message dans lâ€™un. Tu dois le recevoir dans les deux.

**ğŸ’¬ Exemple :**
```bash
> Salut Ã  tous !
```

ğŸŸ¢ Les deux clients doivent afficher Salut Ã  tous !.

---

### 7. ğŸ§ª Tester le Redis Pub/Sub (scalabilitÃ©)

**Ã‰tapes :**
- Lance une deuxiÃ¨me instance de ton backend (dans un autre terminal) :
```bash
go run cmd/main.go
```
- Connecte websocat Ã  chaque instance :
Instance 1 : port `8080`
Instance 2 : change Ã  la volÃ©e : `r.Run(":8081")`, connecte Ã  `ws://localhost:8081/ws`
- Envoie un message sur une instance, il doit apparaÃ®tre sur toutes â†’ preuve que Redis propulse les messages entre les processus backend.

---

### 8. ğŸ§ª VÃ©rifie le JWT en cas d'erreur

Si tu connectes sans Authorization, tu dois recevoir :
```bash
{"error":"Authorization header manquant"}
```
Ou :
```bash
{"error":"Token invalide"}
```
## VIII. PostgreSQL & MongoDB
### 1. Mise en place de PostgreSQL avec pgAdmin
**CrÃ©er la structure Docker pour PostgreSQL + pgAdmin**
Dans `docker-compose.yml`, ajoute la section PostgreSQL + pgAdmin :
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:16
    container_name: nubo_postgres
    environment:
      POSTGRES_USER: nubo_user
      POSTGRES_PASSWORD: nubo_password
      POSTGRES_DB: nubo_db
    ports:
      - "5432:5432"
    volumes:
      - ./postgres-data:/var/lib/postgresql/data

  pgadmin:
    image: dpage/pgadmin4
    container_name: nubo_pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@nubo.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "8082:80"
```
**DÃ©marre les services :**
`docker-compose -f docker-compose.yml up -d`
**RÃ©sultat attendu :**
PostgreSQL accessible sur `localhost:5432`
pgAdmin accessible sur http://localhost:8082
Tu peux connecter pgAdmin Ã  PostgreSQL avec nubo_user / nubo_password
**CrÃ©er les dossiers pour les scripts SQL**
Arborescence suggÃ©rÃ©e :
```bash
Nubo/
â”œâ”€ docker/
â”‚  â””â”€ docker-compose.yml
â”œâ”€ sql/
â”‚  â”œâ”€ init/       # Scripts de crÃ©ation de tables de base
â”‚  â”œâ”€ functions/  # ProcÃ©dures stockÃ©es, triggers
â”‚  â””â”€ views/      # Vues SQL
```
Place tes fichiers `.sql` dans ces dossiers selon leur rÃ´le.

---

### 2. Mise en place de MongoDB avec mongo-express
**Ajouter MongoDB Ã  Docker**
Toujours dans `docker-compose.yml`, ajoute :
```yaml
  mongo:
    image: mongo:7
    container_name: nubo_mongo
    ports:
      - "27017:27017"
    volumes:
      - ./mongo-data:/data/db

  mongo-express:
    image: mongo-express:1.0.0
    container_name: nubo_mongo_express
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: example
      ME_CONFIG_MONGODB_SERVER: mongo
    ports:
      - "8083:8081"
```
**DÃ©marre le service :**
`docker-compose -f docker-compose.yml up -d`
MongoDB accessible sur `localhost:27017`
mongo-express accessible sur http://localhost:8083
**Arborescence pour les scripts Mongo**
```bash
Nubo/
â”œâ”€ mongo/
â”‚  â”œâ”€ init/          # CrÃ©ation des collections, index, sharding
â”‚  â”œâ”€ scripts/       # Inserts, indexes, TTL commands
â”‚  â””â”€ workers/       # Workers pour traitement asynchrone
```

---

## IX. Ã‰criture dans les bases
### 1. RÃ¨gle dâ€™or (rappel rapide)
- **PostgreSQL** = systÃ¨me de vÃ©ritÃ©, intÃ©gritÃ©, contraintes, requÃªtes relationnelles (users, follow, paramÃ¨tres, archival Ã  vie).
- **MongoDB** = charge volatile/haut-volume, accÃ¨s par documents, donnÃ©es massives / flexibles / derniÃ¨re pÃ©riode (cache, messages rÃ©cents, logs).
- Redis = stockage en mÃ©moire pour sessions / liste dâ€™utilisateurs en ligne / counters / pubsub (dÃ©jÃ  en place).

### 2. Arborescence globale (haute niveau)
```bash
PostgreSQL
â”œâ”€ users
â”‚  â”œâ”€ user_settings
â”‚  â”œâ”€ sessions (refresh tokens / audit)
â”œâ”€ follows
â”œâ”€ blocks
â”œâ”€ posts
â”‚  â”œâ”€ comments
â”‚  â”œâ”€ likes
â”œâ”€ media (metadata minimal + pointer vers stockage objet)
â”œâ”€ conversations_meta
â”‚  â”œâ”€ conversation_members
â”‚  â”œâ”€ message_index (rÃ©sumÃ©/offset pour messages dans Mongo)
â”œâ”€ reports
â”œâ”€ admin_actions
â””â”€ audit_logs

MongoDB
â”œâ”€ messages                      (messages complets / growth)
â”œâ”€ posts_documents               (post + media metadata volumineux / versions)
â”œâ”€ comments_documents            (ou embedded in posts if small)
â”œâ”€ notifications                 (push & in-app notifications)
â”œâ”€ feed_cache                    (prÃ©-calculÃ©, TTL)
â”œâ”€ user_activity_logs            (clicks, views, events)
â”œâ”€ media_metadata                (vision/thumbnail/ai-tags)
â””â”€ search_index / embeddings     (opti. pour recommandations)
```

### 3. PostgreSQL : Tables clefs (schÃ©ma rÃ©sumÃ©)

> Utiliser UUID (uuid_generate_v4()) pour tous les id en production. Datetime en timestamptz.

**PostgreSQL :**

**users**
- `id uuid PRIMARY KEY`
- `username text UNIQUE NOT NULL`
- `email text UNIQUE NOT NULL`
- `password_hash text NOT NULL`
- `salt text NULL` (si tu utilises scrypt/bcrypt, pas nÃ©cessaire)
- `display_name text`
- `bio text`
- `birthdate date`
- `phone text UNIQUE NULL`
- `profile_picture_id uuid NULL` (rÃ©fÃ©rence dans media)
- `state smallint NOT NULL DEFAULT 1` (1=active, 0=deleted, 2=banned)
- `created_at timestamptz DEFAULT now()`
- `updated_at timestamptz`
**Index** : `ON users (username)`, `ON users (email)`.
```sql
CREATE TABLE IF NOT EXISTS users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique de l'utilisateur
    username TEXT UNIQUE NOT NULL, -- nom d'utilisateur unique
    email TEXT UNIQUE NOT NULL, -- email unique
    email_verified BOOLEAN DEFAULT FALSE, -- email vÃ©rifiÃ©
    phone TEXT UNIQUE, -- numÃ©ro de tÃ©lÃ©phone unique
    phone_verified BOOLEAN DEFAULT FALSE, -- numÃ©ro de tÃ©lÃ©phone vÃ©rifiÃ©
    password_hash TEXT NOT NULL, -- mot de passe hachÃ©
    first_name TEXT NOT NULL, -- prÃ©nom
    last_name TEXT NOT NULL, -- nom de famille
    birthdate DATE, -- date de naissance
    sex SMALLINT, -- sexe
    bio TEXT, -- biographie
    profile_picture_id UUID, -- id de l'image de profil
    grade SMALLINT NOT NULL DEFAULT 1, -- grade de l'utilisateur
    location TEXT, -- localisation de l'utilisateur
    school TEXT, -- Ã©cole
    works TEXT, -- emplois
    badges TEXT[], -- badges
    created_at TIMESTAMPTZ DEFAULT now(), -- date de crÃ©ation
    updated_at TIMESTAMPTZ DEFAULT now() -- date de mise Ã  jour
);

CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
```

---

**user_settings**
- `id uuid PRIMARY KEY`
- `user_id uuid REFERENCES users(id) UNIQUE ON DELETE CASCADE`
- `privacy jsonb` (ex: {"posts":"public","messages":"friends"})
- `notifications jsonb` (per-type on/off)
- `language text`
- `theme text`
**Index** : `ON user_settings (user_id)`.
```sql
CREATE TABLE IF NOT EXISTS user_settings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique des paramÃ¨tres utilisateur
    user_id UUID UNIQUE REFERENCES users(id) ON DELETE CASCADE, -- id unique de l'utilisateur
    privacy JSONB, -- paramÃ¨tres de confidentialitÃ©
    notifications JSONB, -- paramÃ¨tres de notification
    language TEXT, -- langue
    theme SMALLINT NOT NULL DEFAULT 0 -- thÃ¨me clair/sombre
);

CREATE INDEX idx_user_settings_user_id ON user_settings(user_id);
```
---

**sessions (refresh tokens / audit)**
- `id uuid PRIMARY KEY`
- `user_id uuid REFERENCES users(id)`
- `refresh_token text`
- `device_info jsonb`
- `ip inet`
- `created_at timestamptz`
- `expires_at timestamptz`
- `revoked boolean DEFAULT false`
**Index** : `ON sessions (user_id, revoked)`.
```sql
CREATE TABLE IF NOT EXISTS sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique de la session
    user_id UUID REFERENCES users(id), -- id de l'utilisateur
    refresh_token TEXT, -- token de rafraÃ®chissement
    device_info JSONB, -- informations sur l'/les appareil(s)
    ip INET[], -- adresse IP
    created_at TIMESTAMPTZ DEFAULT now(), -- date de crÃ©ation
    expires_at TIMESTAMPTZ, -- date d'expiration
    revoked BOOLEAN DEFAULT FALSE -- session rÃ©voquÃ©e
);

CREATE INDEX idx_sessions_user_id_revoked ON sessions(user_id, revoked);
```
---

**follows**
- `id uuid PRIMARY KEY`
- `follower_id uuid REFERENCES users(id)`
- `followed_id uuid REFERENCES users(id)`
- `state smallint DEFAULT 1 (1=ok, 0=pending, 2=blocked)`
- `created_at timestamptz`
**Unique constraint** : `(follower_id, followed_id)`.
**Index** : `ON follows (followed_id)` pour feed queries.
```sql
CREATE TABLE IF NOT EXISTS follows (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du suivi
    followed_id UUID REFERENCES users(id), -- id de l'utilisateur suivi
    state SMALLINT DEFAULT 1, -- Ã©tat du suivi (2 = amis, 1 = suivi, 0 = inactif, -1 = bloquÃ©)
    created_at TIMESTAMPTZ DEFAULT now(), -- date de crÃ©ation
    UNIQUE(follower_id, followed_id)
);

CREATE INDEX idx_follows_followed_id ON follows(followed_id);
```
---

**posts**
- `id uuid PRIMARY KEY`
- `user_id uuid REFERENCES users(id) NOT NULL`
- `content text` (short textual content)
- `media_ids uuid[]` (pointeurs vers table media ou Mongo)
- `meta jsonb` (mentions, hashtags, extra props)
- `visibility smallint` (0=private,1=friends,2=public)
- `created_at timestamptz`
- `updated_at timestamptz`
**Index** : `ON posts (user_id, created_at DESC)` ; `GIN index ON posts (meta jsonb)` pour recherches.
```sql
CREATE TABLE IF NOT EXISTS posts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du post
    user_id UUID REFERENCES users(id) NOT NULL, -- id de l'utilisateur
    content TEXT, -- contenu du post
    media_ids UUID[], -- ids des mÃ©dias associÃ©s
    meta JSONB, -- mÃ©tadonnÃ©es
    visibility SMALLINT DEFAULT 0, -- visibilitÃ© (1 = amis, 0 = public)
    location TEXT, -- localisation
    created_at TIMESTAMPTZ DEFAULT now(), -- date de crÃ©ation
    updated_at TIMESTAMPTZ DEFAULT now() -- date de mise Ã  jour
);

CREATE INDEX idx_posts_user_created ON posts(user_id, created_at DESC);
CREATE INDEX idx_posts_meta ON posts USING GIN(meta);
```
---

**comments**
- `id uuid PRIMARY KEY`
- `post_id uuid REFERENCES posts(id) ON DELETE CASCADE`
- `user_id uuid REFERENCES users(id)`
- `content text`
- `created_at timestamptz`
**Index:** `ON comments (post_id, created_at DESC)`.
```sql
CREATE TABLE IF NOT EXISTS comments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du commentaire
    post_id UUID REFERENCES posts(id) ON DELETE CASCADE, -- id du post
    user_id UUID REFERENCES users(id), -- id de l'utilisateur
    content TEXT, -- contenu du commentaire
    created_at TIMESTAMPTZ DEFAULT now() -- date de crÃ©ation
);

CREATE INDEX idx_comments_post_created ON comments(post_id, created_at DESC);
```
---

**likes**
- `id uuid PRIMARY KEY`
- `target_type text (post/comment)`
- `target_id uuid`
- `user_id uuid REFERENCES users(id)`
- `created_at timestamptz`
**Unique** `(target_type, target_id, user_id)`.
**Index** : `ON likes (target_type, target_id)`.
```sql
CREATE TABLE IF NOT EXISTS likes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du like
    target_type SMALLINT NOT NULL, -- type de la cible (0 = post, 1 = message, 2 = commentaire)
    target_id UUID NOT NULL, -- id de la cible
    user_id UUID REFERENCES users(id), -- id de l'utilisateur
    created_at TIMESTAMPTZ DEFAULT now(), -- date de crÃ©ation
    UNIQUE(target_type, target_id, user_id)
);

CREATE INDEX idx_likes_target ON likes(target_type, target_id);
```
---

**conversations_meta**
- `id uuid PRIMARY KEY`
- `type smallint` (1=direct,2=group)
- `title text NULL`
- `last_message_text text NULL`
- `last_message_time timestamptz NULL`
- `created_at timestamptz`
**Index** : `ON conversations_meta (last_message_time DESC)`.
```sql
CREATE TABLE IF NOT EXISTS conversations_meta (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique de la conversation
    type SMALLINT, -- type de la conversation (0 = message privÃ©e, 1 = groupe, 2 = communautÃ©, 3 = annonce)
    title TEXT, -- titre de la conversation
    last_message_id UUID UNIQUE, -- id du dernier message
    state SMALLINT DEFAULT 0, -- Ã©tat de la conversation (0 = active, 1 = archivÃ©e, 2 = supprimÃ©e)
    created_at TIMESTAMPTZ DEFAULT now() -- date de crÃ©ation
);

CREATE INDEX idx_conversations_last_message ON conversations_meta(last_message_id);
```
---

**conversation_members**
- `id uuid PRIMARY KEY`
- `conversation_id uuid REFERENCES conversations_meta(id)`
- `user_id uuid REFERENCES users(id)`
- `role smallint` (admin/member)
- `joined_at timestamptz`
- `unread_count int DEFAULT 0`

**Unique** `(conversation_id, user_id)`.
```sql
CREATE TABLE IF NOT EXISTS conversation_members (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du membre
    conversation_id UUID REFERENCES conversations_meta(id), -- id de la conversation
    user_id UUID REFERENCES users(id), -- id de l'utilisateur
    role SMALLINT DEFAULT 0, -- rÃ´le du membre (0 = membre, 1 = admin, 2 = crÃ©ateur)
    joined_at TIMESTAMPTZ DEFAULT now(), -- date d'adhÃ©sion
    unread_count INT DEFAULT 0, -- nombre de messages non lus
    UNIQUE(conversation_id, user_id)
);
```
---

**message_index (rÃ©sumÃ© pour accÃ¨s rapide)**
- `id uuid PRIMARY KEY` (same as Mongo message id or index)
- `conversation_id uuid REFERENCES conversations_meta(id)`
- `message_id text` (id in Mongo or pointer)
- `sender_id uuid`
- `created_at timestamptz`
- `snippet text` (first X chars)
**Index**: `ON message_index (conversation_id, created_at DESC)`.
**Pattern** : on Ã©crit le message complet dans MongoDB (champ texte, medias), et on Ã©crit une ligne dâ€™index/minimale en Postgres (message_index) pour permettre recherche pagination rapide, jointures, quotas, unread counters, etc.
```sql
CREATE TABLE IF NOT EXISTS message_index (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du message
    conversation_id UUID REFERENCES conversations_meta(id), -- id de la conversation
    sender_id UUID NOT NULL, -- id de l'expÃ©diteur
    message_type SMALLINT NOT NULL DEFAULT 0, -- 0=text, 1=image, 2=publication, 3=vocal, 4=vidÃ©o
    content TEXT, -- contenu du message
    attachments JSONB, -- pointeurs vers fichiers S3 / metadata
    created_at TIMESTAMPTZ DEFAULT now(), -- date de crÃ©ation
);


CREATE INDEX idx_message_index_conv_created ON message_index(conversation_id, created_at DESC);
```
---

**media (minimum metadata)**
- `id uuid PRIMARY KEY`
- `owner_id uuid`
- `storage_path text` (S3 path)
- `mime text`
- `size bigint`
- `width int, height int`
- `created_at timestamptz`
- `processing_state smallint` (0=pending,1=done)
**Index** : `ON media (owner_id)`.
```sql
CREATE TABLE IF NOT EXISTS media (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du mÃ©dia
    owner_id UUID REFERENCES users(id), -- id du propriÃ©taire
    storage_path TEXT, -- chemin de stockage
    created_at TIMESTAMPTZ DEFAULT now(), -- date de crÃ©ation
);

CREATE INDEX idx_media_owner ON media(owner_id);
CREATE INDEX idx_media_created ON media(created_at);
```
---

**reports**
```sql
CREATE TABLE IF NOT EXISTS reports (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du rapport
    actor_id UUID REFERENCES users(id), -- id de l'utilisateur ayant signalÃ©
    target_type SMALLINT NOT NULL, -- type de la cible (user/post/comment/etc)
    target_id UUID NOT NULL, -- id de la cible
    reason TEXT, -- raison du signalement
    state SMALLINT DEFAULT 0, -- Ã©tat du rapport (0=pending, 1=reviewed, 2=resolved)
    created_at TIMESTAMPTZ DEFAULT now() -- date de crÃ©ation
);

CREATE INDEX idx_reports_actor ON reports(actor_id);
CREATE INDEX idx_reports_created ON reports(created_at);
```

### 4. PosgreSQL : SchÃ©ma
```bash
ğŸ“‚ database/
 â”œâ”€â”€ ğŸ“‚ schemas/
 â”‚    â”œâ”€â”€ auth/          â†’ utilisateurs, sessions, relations
 â”‚    â”œâ”€â”€ content/       â†’ posts, comments, likes, media
 â”‚    â”œâ”€â”€ messaging/     â†’ conversations, messages
 â”‚    â”œâ”€â”€ moderation/    â†’ reports
 â”‚    â”œâ”€â”€ logic/         â†’ fonctions + procÃ©dures
 â”‚    â”œâ”€â”€ views/         â†’ vues matÃ©rialisÃ©es ou non
```

---

### 5. MongoDB
> Principe : stocker documents volumineux, formats libres, TTL sur ce qui est Ã©phÃ©mÃ¨re.
**MongoExpress**
- CrÃ©er une nouvelle base `nubo_recent`
**Terminal**
1. Mets ton Homebrew Ã  jour :
```bash
brew update
```
2. Installe mongosh :
```bash
brew install mongosh
```
3. VÃ©rifie que Ã§a marche :
```bash
mongosh --version
```
**Se connecter Ã  ton serveur Mongo**
Une fois installÃ©, tu pourras te connecter Ã  ton serveur MongoDB (celui oÃ¹ Mongo Express est branchÃ©).
En gÃ©nÃ©ral, si câ€™est en local :
```bash
mongosh "mongodb://root:example@localhost:27017"
```
Tu choisis la base (si ce nâ€™est pas encore fait) :
```javascript
use nubo_recent
```
Ensuite tu colles ton script complet :
(voir collection)
---

**messages (collection)**
```javascript
// ---------------------- USERS ----------------------
db.createCollection("users_recent");
db.users_recent.createIndex({ username: 1 }, { unique: true });
db.users_recent.createIndex({ email: 1 }, { unique: true });

// Exemple dâ€™insertion complÃ¨te pour users_recent
db.users_recent.insertOne({
    _id: UUID(),
    username: "",
    email: "",
    email_verified: false,
    phone: null,
    phone_verified: false,
    password_hash: "",
    first_name: "",
    last_name: "",
    birthdate: null,
    sex: null,
    bio: "",
    profile_picture_id: null,
    grade: 1,
    location: "",
    school: "",
    work: "",
    badges: [],
    created_at: new Date(),
    updated_at: new Date(),
    connected: false
});

// ---------------------- USER SETTINGS ----------------------
db.createCollection("user_settings_recent");
db.user_settings_recent.createIndex({ user_id: 1 }, { unique: true });

db.user_settings_recent.insertOne({
    _id: UUID(),
    user_id: UUID(),
    privacy: {},
    notifications: {},
    language: "",
    theme: 0,
    created_at: new Date(),
    updated_at: new Date()
});

// ---------------------- SESSIONS ----------------------
db.createCollection("sessions_recent");
db.sessions_recent.createIndex({ user_id: 1, revoked: 1 });

db.sessions_recent.insertOne({
    _id: UUID(),
    user_id: UUID(),
    refresh_token: "",
    device_info: {},
    ip: [],
    created_at: new Date(),
    expires_at: null,
    revoked: false
});

// ---------------------- RELATIONS ----------------------
db.createCollection("relations_recent");
db.relations_recent.createIndex({ primary_id: 1 });
db.relations_recent.createIndex({ secondary_id: 1 });
db.relations_recent.createIndex({ secondary_id: 1, primary_id: 1 }, { unique: true });

db.relations_recent.insertOne({
    _id: UUID(),
    primary_id: UUID(),
    secondary_id: UUID(),
    state: 1,
    created_at: new Date()
});

// ---------------------- POSTS ----------------------
db.createCollection("posts_recent");
db.posts_recent.createIndex({ user_id: 1, created_at: -1 });

db.posts_recent.insertOne({
    _id: UUID(),
    user_id: UUID(),
    content: "",
    media_ids: [],
    visibility: 0,
    location: "",
    created_at: new Date(),
    updated_at: new Date()
});

// ---------------------- COMMENTS ----------------------
db.createCollection("comments_recent");
db.comments_recent.createIndex({ post_id: 1, created_at: -1 });

db.comments_recent.insertOne({
    _id: UUID(),
    post_id: UUID(),
    user_id: UUID(),
    content: "",
    created_at: new Date()
});

// ---------------------- LIKES ----------------------
db.createCollection("likes_recent");
db.likes_recent.createIndex({ target_type: 1, target_id: 1 });
db.likes_recent.createIndex({ target_type: 1, target_id: 1, user_id: 1 }, { unique: true });

db.likes_recent.insertOne({
    _id: UUID(),
    target_type: 0,
    target_id: UUID(),
    user_id: UUID(),
    created_at: new Date()
});

// ---------------------- MEDIA ----------------------
db.createCollection("media_recent");
db.media_recent.createIndex({ owner_id: 1 });
db.media_recent.createIndex({ created_at: 1 });

db.media_recent.insertOne({
    _id: UUID(),
    owner_id: UUID(),
    storage_path: "",
    created_at: new Date()
});

// ---------------------- CONVERSATIONS META ----------------------
db.createCollection("conversations_recent");
db.conversations_recent.createIndex({ last_message_id: 1 });

db.conversations_recent.insertOne({
    _id: UUID(),
    type: 0,
    title: "",
    last_message_id: null,
    state: 0,
    created_at: new Date()
});

// ---------------------- CONVERSATION MEMBERS ----------------------
db.createCollection("conversation_members_recent");
db.conversation_members_recent.createIndex({ conversation_id: 1, user_id: 1 }, { unique: true });

db.conversation_members_recent.insertOne({
    _id: UUID(),
    conversation_id: UUID(),
    user_id: UUID(),
    role: 0,
    joined_at: new Date(),
    unread_count: 0
});

// ---------------------- MESSAGES ----------------------
db.createCollection("messages_recent");
db.messages_recent.createIndex({ conversation_id: 1, created_at: -1 });

db.messages_recent.insertOne({
    _id: UUID(),
    conversation_id: UUID(),
    sender_id: UUID(),
    message_type: 0,
    state: 0,
    content: "",
    attachments: {},
    created_at: new Date()
});

// ---------------------- FEED CACHE ----------------------
db.createCollection("feed_cache");
db.feed_cache.createIndex({ user_id: 1, created_at: -1 });

db.feed_cache.insertOne({
    _id: UUID(),
    user_id: UUID(),
    items: [],
    created_at: new Date()
});
```

---

## X. StratÃ©gie de requÃªtes des donnÃ©es :

### 1. StratÃ©gie MongoDB rÃ©ajustÃ©e
1. RÃ©pliquer uniquement les donnÃ©es â€œinteractivesâ€ du dernier mois :
- Interactions = lecture, Ã©criture, modification, likes, commentaires, etc.
- MongoDB ne reÃ§oit que ce sous-ensemble des tables concernÃ©es (`users`, `sessions`, `posts`, `comments`, `likes`, `media`, `messages`, `conversations_meta`, `conversation_members`, `relations`).
- On ne fait pas de rÃ©plication totale. Câ€™est donc bien un filtrage cÃ´tÃ© Go, pas PostgreSQL.
2. Feed prÃ©-calculÃ©
- Continu pour les utilisateurs connectÃ©s.
- Occasionnel pour les utilisateurs non connectÃ©s, selon la charge serveur.
3. DÃ©cision de rÃ©pliquer / stocker les donnÃ©es :
- Exclusivement cÃ´tÃ© Go, qui connaÃ®t la logique mÃ©tier et peut filtrer les donnÃ©es â€œrÃ©centes ou activesâ€.
- PostgreSQL nâ€™est utilisÃ© que comme source de vÃ©ritÃ© pour les donnÃ©es anciennes ou massives.
4. Lecture multi-couche :
```text
Go cherche un message/post :
-> Redis (cache ultra rapide)
-> Mongo (donnÃ©es rÃ©centes ou lourdes)
-> PostgreSQL (historique ou requÃªtes complexes)
```
- On peut sauter des Ã©tapes si on sait dÃ©jÃ  que la donnÃ©e est ancienne ou que le filtre limite Ã  moins dâ€™un mois.
5. Ã‰criture / suppression :
- Ã‰criture triple : Redis + Mongo + PostgreSQL.
- Suppression / update : idem, pour garder la cohÃ©rence.

---

### 2. Optimisation de la fil dâ€™attente et des Ã©critures massives
**PostgreSQL**
- Batch insertions : plutÃ´t que dâ€™Ã©crire 50â€¯000 lignes une par une, grouper les inserts dans une seule requÃªte `INSERT ... VALUES (...), (...), (...)`.
- Transactions groupÃ©es : encapsuler plusieurs opÃ©rations dans une seule transaction rÃ©duit les commits, ce qui accÃ©lÃ¨re les Ã©critures et limite la fragmentation.
- COPY : pour des gros volumes, `COPY FROM` est beaucoup plus rapide quâ€™un `INSERT` classique.
- Prepared statements : si on fait beaucoup dâ€™inserts similaires, prÃ©parer la requÃªte et lâ€™exÃ©cuter en boucle rÃ©duit lâ€™overhead.
- Indexes : dÃ©sactiver temporairement certains indexes pendant un bulk insert massif puis les reconstruire peut Ãªtre plus rapide.
**MongoDB**
- insertMany : Mongo gÃ¨re trÃ¨s bien les insertions en masse via `insertMany`.
- Ordered=false : permet de continuer lâ€™insertion mÃªme si certains documents Ã©chouent, utile pour les trÃ¨s gros batchs.
- Bulk API : `bulkWrite` permet de combiner insert, update, delete dans une seule opÃ©ration, trÃ¨s efficace pour la rÃ©plication / traitement de flux.
- Sharding : si le dataset devient massif, sharder sur une clÃ© qui rÃ©partit uniformÃ©ment la charge dâ€™Ã©criture (ex : `conversation_id` pour messages).
- Write concern : ajuster le write concern (`w=1` pour rapide, `w=majority` pour sÃ»r) selon le besoin.
**GÃ©nÃ©ral**
- Parallelisation cÃ´tÃ© Go :
	- Regrouper les Ã©critures par type et table.
	- Faire plusieurs goroutines pour envoyer les batchs en parallÃ¨le.
	- Redis est naturellement rapide pour des mises Ã  jour concurrentes.

---

### 3. SchÃ©ma conceptuel clair du flux multi-couche
```pgsql
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚       Utilisateur     â”‚
                        â”‚   (Mobile / Web)      â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚       Go        â”‚
                           â”‚  Orchestrateur  â”‚
                           â”‚   logique mÃ©tierâ”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                            â”‚                            â”‚
      â–¼                            â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Redis     â”‚           â”‚     MongoDB     â”‚         â”‚  PostgreSQL     â”‚
â”‚  Cache rapide â”‚           â”‚ DonnÃ©es rÃ©centesâ”‚         â”‚ Source de vÃ©ritÃ©â”‚
â”‚  - unread     â”‚           â”‚ < 1 mois /      â”‚         â”‚ historique      â”‚
â”‚    counters   â”‚           â”‚ interactions    â”‚         â”‚ - toutes tables â”‚
â”‚  - sessions   â”‚           â”‚ - messages      â”‚         â”‚ - contraintes   â”‚
â”‚  - pub/sub    â”‚           â”‚ - posts volum.  â”‚         â”‚   dâ€™intÃ©gritÃ©   â”‚
â”‚  - feed cache â”‚           â”‚ - conversations â”‚         â”‚ - requÃªtes      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   rÃ©centes      â”‚         â”‚   complexes     â”‚
                            â”‚ - medias rÃ©centsâ”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Batch / Bulk insertions â”‚
                       â”‚   insertMany / COPY       â”‚
                       â”‚   Parallelisation Go      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**Explications du flux**
1. Utilisateur interagit â†’ envoie une requÃªte Ã  Go.
2. Go dÃ©cide :
	- Lire â†’ Redis â†’ MongoDB â†’ PostgreSQL si nÃ©cessaire.
	- Ã‰crire â†’ Redis + MongoDB + PostgreSQL.
	- Supprimer â†’ Redis + MongoDB + PostgreSQL.
3. MongoDB contient uniquement les donnÃ©es rÃ©centes ou utilisÃ©es activement (moins dâ€™un mois, interactions rÃ©centes).
4. Redis sert pour :
	- compteur de messages non lus,
	- sessions actives,
	- pub/sub temps rÃ©el,
	- feed cache temporaire.
5. PostgreSQL reste la source de vÃ©ritÃ© complÃ¨te, historique, contraintes dâ€™intÃ©gritÃ©, et requÃªtes complexes (rapports, exports, analytics).

---

**Optimisation / charge serveur**
- Go peut batcher les insertions :
	- Messages, posts, commentaires â†’ insertMany pour Mongo, COPY ou multi-row insert pour PostgreSQL.
- Feed prÃ©-calculÃ© :
	- Pour les utilisateurs connectÃ©s â†’ continu.
	- Pour les non-connectÃ©s â†’ seulement quand charge CPU/RAM le permet (heures creuses).
- Lecture / filtre :
	- PrÃ©-filtrer par moins dâ€™un mois â†’ MongoDB.
	- Si besoin historique â†’ PostgreSQL.

## XI. Travail sur Go
### 1. Initialisation de Redis et Mongo :
__**Objectif :**__
- Forcer Ã  la supprÃ©sion toutes les lignes ayant Ã©tÃ© utilisÃ© il y a plus d'un mois dans les collections de MongoDB dans la base `nubo_recent`
- Nettoyer totalement Redis

**CrÃ©ation de `init.go` et insertion de la directive dans `main.go`**
```go
package initdata

import (
    "context"
    "log"
    "time"

    "github.com/QuentinRegnier/nubo-backend/internal/cache"
    "github.com/QuentinRegnier/nubo-backend/internal/db"
    "go.mongodb.org/mongo-driver/bson"
)

func CleanMongo() {
    ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
    defer cancel()

    dbRecent := db.MongoClient.Database("nubo_recent")

    // RÃ©cupÃ¨re toutes les collections de la DB
    collections, err := dbRecent.ListCollectionNames(ctx, bson.D{})
    if err != nil {
        log.Printf("âŒ Erreur rÃ©cupÃ©ration collections Mongo: %v", err)
        return
    }

    // Date limite : 30 jours
    threshold := time.Now().AddDate(0, 0, -30)

    for _, collName := range collections {
        coll := dbRecent.Collection(collName)

        // Supprime les documents dont last_use < threshold
        filter := bson.M{
            "last_use": bson.M{
                "$lt": threshold,
            },
        }

        res, err := coll.DeleteMany(ctx, filter)
        if err != nil {
            log.Printf("âŒ Erreur suppression dans %s: %v", collName, err)
            continue
        }

        log.Printf("ğŸ§¹ Nettoyage Mongo [%s] â†’ %d documents supprimÃ©s", collName, res.DeletedCount)
    }
}

func CleanRedis() {
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()

    err := cache.Rdb.FlushDB(ctx).Err()
    if err != nil {
        log.Printf("âŒ Erreur flush Redis: %v", err)
        return
    }
    log.Println("ğŸ§¹ Redis vidÃ© avec succÃ¨s âœ…")
}

func InitData() {
    log.Println("=== Initialisation: Nettoyage Mongo + Redis ===")
    CleanMongo()
    CleanRedis()
    log.Println("=== Initialisation terminÃ©e âœ… ===")
}
```
```go
// Nettoyage au dÃ©marrage
    initdata.InitData()
```

---

### 2. SÃ©curisation par JWT 
- mise en place d'une expiration dans le token
- mise en place de la connexion du JWT_SCRET dans celui dans `.env`
```go 
package api

import (
	"fmt"
	"net/http"
	"os"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/golang-jwt/jwt/v5"
)

func JWTMiddleware() gin.HandlerFunc {
	return func(c *gin.Context) {
		tokenString := c.GetHeader("Authorization")
		if tokenString == "" {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Authorization header manquant"})
			return
		}

		// Retirer "Bearer " si prÃ©sent
		if len(tokenString) > 7 && tokenString[:7] == "Bearer " {
			tokenString = tokenString[7:]
		}

		keyFunc := func(token *jwt.Token) (interface{}, error) {
			if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
				return nil, fmt.Errorf("algorithme JWT invalide")
			}
			return []byte(os.Getenv("JWT_SECRET")), nil
		}

		token, err := jwt.Parse(tokenString, keyFunc)
		if err != nil || !token.Valid {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Token invalide"})
			return
		}

		claims, ok := token.Claims.(jwt.MapClaims)
		if !ok || !token.Valid {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Claims invalides"})
			return
		}

		// VÃ©rification expiration
		if exp, ok := claims["exp"].(float64); ok {
			if time.Now().After(time.Unix(int64(exp), 0)) {
				c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Token expirÃ©"})
				return
			}
		}

		// Mettre lâ€™ID utilisateur dans le contexte
		c.Set("userID", claims["sub"])

		c.Next()
	}
}
```

---

### 3. Dynamisation de la gestion de la RAM pour REDIS et crÃ©ation de type de noeud
- type **flux** : permet d'envoyer des donnÃ©es Ã  d'autre WS, durÃ©e de vie des donnÃ©es 1s
- type **cache** : permet de stocker des donnÃ©es pour soulager MongoDB et PostgreSQL ainsi que pour augmenter la vitesse, durÃ©e de vie des donnÃ©es infini ou presque
- gestion intÃ©lligente de la RAM avec une marge laissÃ© vide Ã  ne pas dÃ©passer sinon le programme purge les donnÃ©es les moins utilisÃ© de REDIS, ce sont bien les donnÃ©es qui sont purger et pas les noeuds entier
```go
// internal/cache/strategy_redis.go
package cache

import (
	"context"
	"log"
	"runtime"
	"sync"
	"time"

	"github.com/go-redis/redis/v8"
)

// ---------------- Types ----------------

// Type dâ€™un noeud Redis
type NodeType int

const (
	NodeFlux NodeType = iota
	NodeCache
)

// Un Ã©lÃ©ment dans la LRU globale
type CacheElement struct {
	NodeName  string // nom du noeud (ex: "messages")
	ElementID string // ex: "392"
	prev      *CacheElement
	next      *CacheElement
}

// LRU globale pour les Ã©lÃ©ments de type cache
type LRUCache struct {
	elements map[string]*CacheElement // clÃ© = nodeName:elementID
	head     *CacheElement
	tail     *CacheElement
	mu       sync.Mutex
	rdb      *redis.Client
}

// ---------------- Initialisation ----------------

// NewLRUCache initialise un cache LRU global
func NewLRUCache(rdb *redis.Client) *LRUCache {
	return &LRUCache{
		elements: make(map[string]*CacheElement),
		rdb:      rdb,
	}
}

// ---------------- Gestion usage ----------------

// MarkUsed marque un Ã©lÃ©ment comme utilisÃ© (move to tail)
func (lru *LRUCache) MarkUsed(nodeName, elementID string) {
	lru.mu.Lock()
	defer lru.mu.Unlock()

	key := nodeName + ":" + elementID
	elem, exists := lru.elements[key]
	if exists {
		lru.moveToTail(elem)
		return
	}

	elem = &CacheElement{NodeName: nodeName, ElementID: elementID}
	lru.elements[key] = elem
	lru.append(elem)
}

func (lru *LRUCache) moveToTail(elem *CacheElement) {
	if elem == lru.tail {
		return
	}
	lru.remove(elem)
	lru.append(elem)
}

func (lru *LRUCache) append(elem *CacheElement) {
	if lru.tail != nil {
		lru.tail.next = elem
		elem.prev = lru.tail
		elem.next = nil
		lru.tail = elem
	} else {
		lru.head = elem
		lru.tail = elem
	}
}

func (lru *LRUCache) remove(elem *CacheElement) {
	if elem.prev != nil {
		elem.prev.next = elem.next
	} else {
		lru.head = elem.next
	}
	if elem.next != nil {
		elem.next.prev = elem.prev
	} else {
		lru.tail = elem.prev
	}
	elem.prev = nil
	elem.next = nil
}

func (lru *LRUCache) purgeOldest() {
	if lru.head == nil {
		return
	}
	old := lru.head
	log.Printf("Purging Redis cache element (LRU): node=%s, id=%s\n", old.NodeName, old.ElementID)
	lru.remove(old)
	delete(lru.elements, old.NodeName+":"+old.ElementID)

	// suppression dans Redis
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	key := "cache:" + old.NodeName
	if err := lru.rdb.HDel(ctx, key, old.ElementID).Err(); err != nil {
		log.Printf("Erreur suppression Redis: %v\n", err)
	}
}

// ---------------- MÃ©moire ----------------

// StartMemoryWatcher surveille la RAM
func (lru *LRUCache) StartMemoryWatcher(maxRAM uint64, marge uint64, interval time.Duration) {
	go func() {
		for {
			var m runtime.MemStats
			runtime.ReadMemStats(&m)
			used := m.Alloc
			if maxRAM == 0 {
				maxRAM = getTotalRAM()
			}
			if used > maxRAM-marge {
				log.Printf("RAM utilisÃ©e=%d, dÃ©passement seuil=%d, purge LRU...\n", used, maxRAM-marge)
				lru.mu.Lock()
				lru.purgeOldest()
				lru.mu.Unlock()
			}
			time.Sleep(interval)
		}
	}()
}

func getTotalRAM() uint64 {
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	return m.Sys
}

// ---------------- Flux ----------------

// DefaultFluxTTL est le temps de vie par dÃ©faut d'un message de flux
const DefaultFluxTTL = 1 * time.Second

// PushFluxWithTTL publie un message sur un flux et crÃ©e un TTL individuel
func PushFluxWithTTL(rdb *redis.Client, nodeName string, messageID string, message []byte, ttl time.Duration) error {
	ctx := context.Background()

	// Stocke le message temporairement avec TTL individuel
	key := "fluxmsg:" + messageID
	if err := rdb.Set(ctx, key, message, ttl).Err(); err != nil {
		return err
	}

	// Publie sur le canal pour diffusion immÃ©diate
	channel := "flux:" + nodeName
	if err := rdb.Publish(ctx, channel, messageID).Err(); err != nil {
		return err
	}

	return nil
}

// SubscribeFlux s'abonne Ã  un flux et renvoie les messages via un channel Go
func SubscribeFlux(rdb *redis.Client, nodeName string) (<-chan []byte, context.CancelFunc) {
	channel := "flux:" + nodeName
	ctx, cancel := context.WithCancel(context.Background())

	pubsub := rdb.Subscribe(ctx, channel)
	ch := make(chan []byte, 100) // buffer cÃ´tÃ© Go

	go func() {
		defer pubsub.Close()
		for msg := range pubsub.Channel() {
			messageID := msg.Payload
			// RÃ©cupÃ¨re le message stockÃ© temporairement
			data, err := rdb.Get(ctx, "fluxmsg:"+messageID).Bytes()
			if err == redis.Nil {
				continue // TTL dÃ©jÃ  expirÃ©
			} else if err != nil {
				log.Println("Erreur rÃ©cupÃ©ration flux message:", err)
				continue
			}
			ch <- data
		}
		close(ch)
	}()

	return ch, cancel
}

// ---------------- Cache ----------------

// SetCache ajoute un Ã©lÃ©ment au cache
func (lru *LRUCache) SetCache(ctx context.Context, nodeName, elementID string, value []byte) error {
	key := "cache:" + nodeName
	if err := lru.rdb.HSet(ctx, key, elementID, value).Err(); err != nil {
		return err
	}
	lru.MarkUsed(nodeName, elementID)
	return nil
}

// GetCache lit un Ã©lÃ©ment du cache
func (lru *LRUCache) GetCache(ctx context.Context, nodeName, elementID string) ([]byte, error) {
	key := "cache:" + nodeName
	val, err := lru.rdb.HGet(ctx, key, elementID).Bytes()
	if err == redis.Nil {
		return nil, nil
	}
	if err == nil {
		lru.MarkUsed(nodeName, elementID)
	}
	return val, err
}

// ---------------- Global ----------------

// GlobalStrategy est lâ€™instance globale de stratÃ©gie LRU utilisÃ©e par toute lâ€™app
var GlobalStrategy *LRUCache
```
et dapatation du nouveau systÃ¨me dans le `hub.go` :
```go 
package websocket

import (
	"crypto/rand"
	"encoding/hex"
	"log"
	"sync"

	"github.com/QuentinRegnier/nubo-backend/internal/cache"
	"github.com/gorilla/websocket"
)

// generateMessageID crÃ©e un ID unique pour chaque message
func generateMessageID() string {
	b := make([]byte, 8) // 8 octets â†’ 16 caractÃ¨res hex
	if _, err := rand.Read(b); err != nil {
		return "msg-fallback" // fallback si erreur improbable
	}
	return hex.EncodeToString(b)
}

// ---------------- Clients ----------------

type Client struct {
	conn *websocket.Conn
	send chan []byte
}

// ---------------- Hub ----------------

type Hub struct {
	clients    map[*Client]bool
	register   chan *Client
	unregister chan *Client
	broadcast  chan []byte
	mu         sync.Mutex

	channel string
}

// NewHub crÃ©e un nouveau Hub et lance l'Ã©coute du flux Redis
func NewHub() *Hub {
	h := &Hub{
		clients:    make(map[*Client]bool),
		register:   make(chan *Client),
		unregister: make(chan *Client),
		broadcast:  make(chan []byte),
		channel:    "nubo-websocket",
	}

	// Utilise la fonction SubscribeFlux pour recevoir les messages
	go h.listenFlux()
	return h
}

// listenFlux s'abonne au flux Redis et distribue les messages aux clients
func (h *Hub) listenFlux() {
	ch, cancel := cache.SubscribeFlux(cache.Rdb, h.channel)
	defer cancel()

	for msg := range ch {
		h.mu.Lock()
		for client := range h.clients {
			select {
			case client.send <- msg:
			default:
				close(client.send)
				delete(h.clients, client)
			}
		}
		h.mu.Unlock()
	}
}

// Run dÃ©marre la boucle principale du hub pour gÃ©rer l'inscription/dÃ©sinscription et la diffusion
func (h *Hub) Run() {
	for {
		select {
		case client := <-h.register:
			h.mu.Lock()
			h.clients[client] = true
			h.mu.Unlock()
			log.Println("Client registered")

		case client := <-h.unregister:
			h.mu.Lock()
			if _, ok := h.clients[client]; ok {
				delete(h.clients, client)
				close(client.send)
				log.Println("Client unregistered")
			}
			h.mu.Unlock()

		case message := <-h.broadcast:
			// Publie le message sur le flux Redis avec TTL individuel (ex: 1s)
			messageID := generateMessageID() // fonction pour crÃ©er un ID unique
			err := cache.PushFluxWithTTL(cache.Rdb, h.channel, messageID, message, cache.DefaultFluxTTL)
			if err != nil {
				log.Println("Erreur PushFluxWithTTL:", err)
			}
		}
	}
}

// ---------------- Clients WS ----------------

// ReadPump lit les messages dâ€™un client et les envoie au hub
func (c *Client) ReadPump(hub *Hub) {
	defer func() {
		hub.unregister <- c
		c.conn.Close()
	}()

	for {
		_, msg, err := c.conn.ReadMessage()
		if err != nil {
			log.Println("Read error:", err)
			break
		}

		// TODO: sauvegarder msg en base (Postgres/Mongo)

		// Envoie le message aux autres clients via le hub
		hub.broadcast <- msg
	}
}

// WritePump envoie les messages du hub au client
func (c *Client) WritePump() {
	for msg := range c.send {
		err := c.conn.WriteMessage(websocket.TextMessage, msg)
		if err != nil {
			log.Println("Write error:", err)
			break
		}
	}
	c.conn.Close()
}
```
ajout Ã©galement de la dÃ©claration de l'observation de la RAM dans `main.go` :
```go
// âš¡ Initialiser la stratÃ©gie Redis
<cache.GlobalStrategy = cache.NewLRUCache(cache.Rdb)

// âš¡ DÃ©marrer le watcher mÃ©moire
// maxRAM = 0 => autodÃ©tection
// marge = 200 Mo de marge de sÃ©curitÃ©
// interval = toutes les 2 secondes
cache.GlobalStrategy.StartMemoryWatcher(0, 200*1024*1024, 2*time.Second)
```

---

### 4. Dupliquer le WS pour faire des test de REDIS plus simplement :
```yaml
api1:
  build: .
  container_name: nubo_api1
  ports:
    - "8080:8080"
  env_file:
    - .env
  depends_on:
    - redis
    - postgres
    - mongo
  restart: always

api2:
  build: .
  container_name: nubo_api2
  ports:
    - "8081:8080" # mÃªme port interne, mais exposÃ© sur un port diffÃ©rent
  env_file:
    - .env
  depends_on:
    - redis
    - postgres
    - mongo
  restart: always
```

---

### 5.  GÃ©rer et nouvelle architechture des caches + crÃ©ations des collections
1. `redis_collections.go` :
CrÃ©ation d'un shÃ©ma pour cahcun des base sql :
```go
// MessagesCache
var MessagesSchema = map[string]reflect.Kind{
	"id":              reflect.String,
	"conversation_id": reflect.String,
	"sender_id":       reflect.String,
	"message_type":    reflect.Int,
	"state":           reflect.Int,
	"content":         reflect.String,
	"attachments":     reflect.Map, // JSONB
	"created_at":      reflect.String,
}
```
2. `redis_caches.go` :
- CrÃ©ation d'un systÃ¨me de collections qui servira Ã  partir des shemas Ã  valider la structure des donnÃ©es envoyer Ã  la fonction Set mais aussi intÃ©ragir avec la collections dans le canal cache de REDIS de cette collections.
```go
// ---------------- Collection et schÃ©ma ----------------

type Collection struct {
	Name       string                  // ex: "messages"
	Schema     map[string]reflect.Kind // ex: {"id": reflect.Int, "content": reflect.String}
	Redis      *redis.Client
	LRU        *LRUCache     // pour mettre Ã  jour la LRU si cache
	Expiration time.Duration // TTL par dÃ©faut pour chaque Ã©lÃ©ment, facultatif
}

// NewCollection crÃ©e une collection avec un schÃ©ma et LRU optionnel
func NewCollection(name string, schema map[string]reflect.Kind, rdb *redis.Client, lru *LRUCache) *Collection {
	_, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	// Initialiser les indexs pour chaque champ du schÃ©ma
	for field := range schema {
		if field == "id" {
			continue
		}
		// on ne crÃ©e pas les valeurs ici (elles seront ajoutÃ©es au fur et Ã  mesure)
		// mais on garde la structure logique
		log.Printf("Index initialisÃ© pour collection=%s, champ=%s", name, field)
	}

	return &Collection{
		Name:   name,
		Schema: schema,
		Redis:  rdb,
		LRU:    lru,
	}
}

// ---------------- Validation ----------------

func (c *Collection) validate(obj map[string]any) error {
	for field, kind := range c.Schema {
		val, ok := obj[field]
		if !ok {
			return fmt.Errorf("champ manquant: %s", field)
		}
		if reflect.TypeOf(val).Kind() != kind {
			return fmt.Errorf("champ %s doit Ãªtre de type %s", field, kind.String())
		}
	}
	return nil
}
```
- Cette fonction `NewCollection` introduit surtout une nouvelle faÃ§on de penser et d'organiser les donnÃ©es dans le cache :
Ancienne structure cache "messages":
```markdown
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Redis Cache         â”‚
â”‚        messages (hash)      â”‚
â”‚                             â”‚
â”‚  id â†’ {full message object} â”‚
â”‚  392 â†’ {id:392, content...} â”‚
â”‚  77  â†’ {id:77, content...}  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         Collection LRU
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ id usage  â”‚
         â”‚ 392, 77   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Notes:
- Recherche par id uniquement.
- Pour trouver par conversation_id ou sender_id, il faut parcourir tous les objets.
- Peu dâ€™index â†’ lente recherche sur critÃ¨res.

-----------------------------------------------------

Nouvelle structure cache "messages":
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Redis Cache         	  â”‚                       â”‚  Index Redis par champ   â”‚
â”‚             messages (hash)             â”‚                       â”‚                          â”‚
â”‚                                         â”‚                       â”‚ state:3 â†’ {392}          â”‚
â”‚  392 â†’ {id:392, conversation_id:49, ...}â”‚           +           â”‚ conv_id:49 â†’ {392, 77}   â”‚
â”‚  77  â†’ {id:77, conversation_id:49, ...} â”‚                       â”‚ conv_id:50 â†’ {283}       â”‚
â”‚  283 â†’ {id:283, conversation_id:50, ...}â”‚                       â”‚ sender_id:462 â†’ {392}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      
                      â”‚
                      â–¼
               Collection LRU
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ id usage per node â”‚
              â”‚ 392 â†’ tail        â”‚
              â”‚ 77  â†’ middle      â”‚
              â”‚ 283 â†’ head        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Notes:
- Recherche rapide par nâ€™importe quel champ indexÃ©.
- Les objets restent dans le hash principal, seul lâ€™index est consultÃ©.
- LRU gÃ¨re la mÃ©moire en supprimant uniquement les Ã©lÃ©ments les moins utilisÃ©s.
- Plus scalable pour filtres complexes comme conversation_id, state, sender_id, etc.
```
- CrÃ©ation de la mÃ©thode `Set` qui permet d'ajouter un Ã©lÃ©ment dans un collection Ã  condition qu'il respecte la structure de la collection Ã  laquelle il compte appartenir. De plus on ajoute cette Ã©lÃ©ment avec son Id dans la liste LRU d'usage des donnÃ©es de faÃ§on Ã  avoir un systÃ¨me de supprÃ©ssion d'Ã©lÃ©ment dans redis cohÃ©rent et continue tous au long de nos interraction avec redis.
```go
// ---------------- Set ----------------

// Set ajoute un Ã©lÃ©ment dans la collection
func (c *Collection) Set(obj map[string]any) error {
	if err := c.validate(obj); err != nil {
		log.Println("Validation Ã©chouÃ©e:", err)
		return err
	}

	id := fmt.Sprintf("%v", obj["id"])
	objKey := "cache:" + c.Name + ":" + id

	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	// Sauvegarde complÃ¨te dans Redis Hash
	if err := c.Redis.HMSet(ctx, objKey, obj).Err(); err != nil {
		return err
	}

	// Mettre Ã  jour les indexs
	for field := range c.Schema {
		if field == "id" {
			continue
		}
		if val, ok := obj[field]; ok {
			valStr := fmt.Sprintf("%v", val)
			idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, valStr)
			if err := c.Redis.SAdd(ctx, idxKey, id).Err(); err != nil {
				log.Printf("Erreur mise Ã  jour index %s: %v", idxKey, err)
			}
		}
	}

	// Mise Ã  jour LRU
	if c.LRU != nil {
		c.LRU.MarkUsed(c.Name, id)
	}

	return nil
}
```
Et elle s'utilise ainsi :
```go
// Ajouter un message
messages := NewCollection("messages", schemaMessages, rdb, lru)

messages.Set(map[string]interface{}{
	"id": 382, "conversation_id": 49, "sender_id": 462,
	"message_type": 0, "state": 3, "content": "my message",
	"attachements": nil, "create_at": "12:34-10-03-2007",
})
```
- CrÃ©ation de la mÃ©thode `Get` qui consite en la recherche d'un Ã©lÃ©ment dans la collection redis, tous l'ambition de cette fonction c'est qu'elle peut accepter un codage de filtre grace Ã  la fonction `matchFilter` qui nous permet de dÃ©crypter le codage qui se base sur un MongoDB-like afin de simplifier l'encodage. La fonction bÃ©nÃ©ficie aussi de la nouvelle structure du cache redis avec l'ajout d'index lui permettant de chercher baucoup plus vite les prÃ©cieux id.
```go
// ---------------- Get ----------------

// Get retourne tous les Ã©lÃ©ments correspondant au filtre (MongoDB-like)
func (c *Collection) Get(filter map[string]any) ([]map[string]any, error) {
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	var candidateIDs []string

	// ğŸ”¹ Ã‰tape 1 : RÃ©duire lâ€™espace de recherche avec les index Redis
	indexKeys := []string{}
	for field, condition := range filter {
		subCond, ok := condition.(map[string]any)
		if !ok {
			// Ã©quivalent $eq direct
			valStr := fmt.Sprintf("%v", condition)
			idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, valStr)
			indexKeys = append(indexKeys, idxKey)
			continue
		}

		for op, val := range subCond {
			switch op {
			case "$eq":
				valStr := fmt.Sprintf("%v", val)
				idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, valStr)
				indexKeys = append(indexKeys, idxKey)

			case "$in":
				arr, ok := val.([]any)
				if ok {
					orKeys := []string{}
					for _, a := range arr {
						valStr := fmt.Sprintf("%v", a)
						idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, valStr)
						orKeys = append(orKeys, idxKey)
					}
					// on mettra Ã§a en union aprÃ¨s
					if len(orKeys) > 0 {
						members, err := c.Redis.SUnion(ctx, orKeys...).Result()
						if err == nil {
							candidateIDs = append(candidateIDs, members...)
						}
					}
				}
			}
		}
	}

	// Si on a plusieurs indexKeys (issus de $eq), on fait une intersection
	if len(indexKeys) == 1 {
		ids, err := c.Redis.SMembers(ctx, indexKeys[0]).Result()
		if err == nil {
			candidateIDs = append(candidateIDs, ids...)
		}
	} else if len(indexKeys) > 1 {
		ids, err := c.Redis.SInter(ctx, indexKeys...).Result()
		if err == nil {
			candidateIDs = append(candidateIDs, ids...)
		}
	}

	// Si aucun index nâ€™a filtrÃ© â†’ on doit scanner tout
	if len(candidateIDs) == 0 {
		pattern := fmt.Sprintf("cache:%s:*", c.Name)
		keys, scanErr := c.Redis.Keys(ctx, pattern).Result()
		if scanErr != nil {
			return nil, scanErr
		}
		for _, k := range keys {
			parts := strings.Split(k, ":")
			candidateIDs = append(candidateIDs, parts[len(parts)-1])
		}
	}

	// ğŸ”¹ Ã‰tape 2 : Charger les objets et appliquer matchFilter
	results := []map[string]any{}
	for _, id := range candidateIDs {
		objKey := "cache:" + c.Name + ":" + id
		data, err := c.Redis.HGetAll(ctx, objKey).Result()
		if err != nil || len(data) == 0 {
			continue
		}

		obj := make(map[string]any)
		for k, v := range data {
			obj[k] = v
		}

		// VÃ©rification complÃ¨te via matchFilter
		match, err := matchFilter(obj, filter)
		if err != nil {
			continue
		}
		if match {
			results = append(results, obj)
			if c.LRU != nil {
				c.LRU.MarkUsed(c.Name, id)
			}
		}
	}

	return results, nil
}
```
Et elle s'utilise ainsi :
```go
// Rechercher tous les Ã©lÃ©ments ayant conversation_id == 49
messages := NewCollection("messages", schemaMessages, rdb, lru)

// Rechercher
results, _ := messages.Get(map[string]interface{}{
	"conversation_id": map[string]interface{}{"$eq": 49},
})
```
- La fonction `matchFilter` a pour objectif de traduire une instruction de filtre json en un vÃ©ritable filtre utilisable dans la fonction `Get` et `Delete`.
Exemple :
```json
{
  "$and": [
    { "status": { "$eq": "active" } },               // Ã©gal Ã  "active"
    { "age": { "$gt": 18 } },                        // supÃ©rieur Ã  18
    { "score": { "$gte": 50 } },                     // supÃ©rieur ou Ã©gal Ã  50
    { "level": { "$lt": 10 } },                      // infÃ©rieur Ã  10
    { "rank": { "$lte": 5 } },                       // infÃ©rieur ou Ã©gal Ã  5
    { "category": { "$ne": "banned" } },            // diffÃ©rent de "banned"
    { "tags": { "$in": ["go", "json"] } },          // contient au moins "go" ou "json"
    { "priority": { "$nin": [0, 1] } },             // ne contient pas 0 ou 1
    { 
      "$or": [                                       // au moins une condition vraie
        { "vip": true },
        { "score": { "$gt": 90 } }
      ]
    },
    {
      "$not": { "region": { "$eq": "EU" } }         // region â‰  EU
    },
    {
      "$nor": [                                      // aucune de ces conditions
        { "blocked": true },
        { "deleted": true }
      ]
    }
  ]
}
```
```go
// matchFilter applique le filtre type MongoDB sur un objet
func matchFilter(obj map[string]any, filter map[string]any) (bool, error) {
	for k, v := range filter {
		if strings.HasPrefix(k, "$") {
			switch k {
			case "$and":
				arr, ok := v.([]any)
				if !ok {
					return false, fmt.Errorf("$and doit Ãªtre un tableau")
				}
				for _, cond := range arr {
					subFilter, ok := cond.(map[string]any)
					if !ok {
						return false, fmt.Errorf("condition $and invalide")
					}
					match, err := matchFilter(obj, subFilter)
					if err != nil || !match {
						return false, err
					}
				}
				return true, nil
			case "$or":
				arr, ok := v.([]any)
				if !ok {
					return false, fmt.Errorf("$or doit Ãªtre un tableau")
				}
				for _, cond := range arr {
					subFilter, ok := cond.(map[string]any)
					if !ok {
						return false, fmt.Errorf("condition $or invalide")
					}
					match, err := matchFilter(obj, subFilter)
					if err == nil && match {
						return true, nil
					}
				}
				return false, nil
			case "$not":
				subFilter, ok := v.(map[string]any)
				if !ok {
					return false, fmt.Errorf("$not doit Ãªtre un objet")
				}
				match, err := matchFilter(obj, subFilter)
				return !match, err
			case "$nor":
				arr, ok := v.([]any)
				if !ok {
					return false, fmt.Errorf("$nor doit Ãªtre un tableau")
				}
				for _, cond := range arr {
					subFilter, ok := cond.(map[string]any)
					if !ok {
						return false, fmt.Errorf("condition $nor invalide")
					}
					match, err := matchFilter(obj, subFilter)
					if err == nil && match {
						return false, nil
					}
				}
				return true, nil
			}
		} else {
			// opÃ©rateurs de comparaison
			subCond, ok := v.(map[string]any)
			if !ok {
				// Ã©quivalent $eq par dÃ©faut
				if obj[k] != v {
					return false, nil
				}
				continue
			}
			for op, val := range subCond {
				switch op {
				case "$eq":
					if obj[k] != val {
						return false, nil
					}
				case "$ne":
					if obj[k] == val {
						return false, nil
					}
				case "$gt":
					if !compareNumbers(obj[k], val, ">") {
						return false, nil
					}
				case "$gte":
					if !compareNumbers(obj[k], val, ">=") {
						return false, nil
					}
				case "$lt":
					if !compareNumbers(obj[k], val, "<") {
						return false, nil
					}
				case "$lte":
					if !compareNumbers(obj[k], val, "<=") {
						return false, nil
					}
				case "$in":
					arr, ok := val.([]any)
					if !ok {
						return false, nil
					}
					found := false
					for _, a := range arr {
						if a == obj[k] {
							found = true
							break
						}
					}
					if !found {
						return false, nil
					}
				case "$nin":
					arr, ok := val.([]any)
					if !ok {
						return false, nil
					}
					for _, a := range arr {
						if a == obj[k] {
							return false, nil
						}
					}
				}
			}
		}
	}
	return true, nil
}
```
- CrÃ©ation de la mÃ©thode `Delete` permettant de supprimer un Ã©lÃ©ment d'une collections redis, pour cela elle utilise la mÃªme technologie de filtrage que dans `Get`. La fonction a un dÃ©fis qui est de supprimer Ã©galement toutes les occurences de l'id dans l'index.
```go
// Delete supprime les Ã©lÃ©ments correspondant au filtre et nettoie les index vides
func (c *Collection) Delete(filter map[string]any) error {
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	// RÃ©cupÃ©rer les objets via Get (filtrage complet)
	objs, err := c.Get(filter)
	if err != nil {
		return err
	}

	pipe := c.Redis.TxPipeline()
	// Stocker les paires idxKey -> id pour vÃ©rifier aprÃ¨s
	type idxCheck struct {
		idxKey string
	}
	var checks []idxCheck

	for _, obj := range objs {
		id := fmt.Sprintf("%v", obj["id"])
		objKey := "cache:" + c.Name + ":" + id

		// Supprimer le hash principal
		pipe.Del(ctx, objKey)

		// Supprimer lâ€™ID de tous les indexs
		for field := range c.Schema {
			if field == "id" {
				continue
			}
			if val, ok := obj[field]; ok {
				valStr := fmt.Sprintf("%v", val)
				idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, valStr)
				pipe.SRem(ctx, idxKey, id)
				checks = append(checks, idxCheck{idxKey: idxKey})
			}
		}

		// Nettoyer la LRU
		if c.LRU != nil {
			c.LRU.mu.Lock()
			delete(c.LRU.elements, c.Name+":"+id)
			c.LRU.mu.Unlock()
		}
	}

	// ExÃ©cuter le pipeline
	if _, err := pipe.Exec(ctx); err != nil {
		log.Printf("Erreur exÃ©cution pipeline delete: %v", err)
		return err
	}

	// VÃ©rifier et supprimer les index vides
	for _, chk := range checks {
		count, err := c.Redis.SCard(ctx, chk.idxKey).Result()
		if err != nil {
			log.Printf("Erreur lecture index %s: %v", chk.idxKey, err)
			continue
		}
		if count == 0 {
			if err := c.Redis.Del(ctx, chk.idxKey).Err(); err != nil {
				log.Printf("Erreur suppression index vide %s: %v", chk.idxKey, err)
			} else {
				log.Printf("Index vide supprimÃ©: %s", chk.idxKey)
			}
		}
	}

	return nil
}
```
Et elle s'utilise ainsi :
```go
// Supprimer tous les Ã©lÃ©ments ayant conversation_id == 49
messages := NewCollection("messages", schemaMessages, rdb, lru)

// Supprimer
messages.Delete(map[string]interface{}{
	"conversation_id": map[string]interface{}{"$eq": 49},
})
```
- CrÃ©ation de la mÃ©thode `Modify` dans le mÃªme style que `Delete` ou `Get` avec des filtres mais on ajoute Ã©galement un catÃ©gorie update qui permet de prÃ©ciser ce que l'on veut changer. Il ya aussi un gros enjeux sur les indexs avec cette fonctions car elle doit tous les actualisers. Comme elle doit actualiser aussi la liste LRU comme d'habitude.
```go
// Modify met Ã  jour les Ã©lÃ©ments correspondant au filtre avec les nouvelles valeurs fournies dans update
func (c *Collection) Modify(filter map[string]interface{}, update map[string]interface{}) error {
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	// RÃ©cupÃ©rer les objets correspondant au filtre
	objs, err := c.Get(filter)
	if err != nil {
		return err
	}

	pipe := c.Redis.TxPipeline()

	for _, obj := range objs {
		id := fmt.Sprintf("%v", obj["id"])
		objKey := "cache:" + c.Name + ":" + id

		// Mettre Ã  jour l'objet avec les nouvelles valeurs
		for field, val := range update {
			obj[field] = val
		}

		// SÃ©rialiser et stocker dans Redis
		data, _ := json.Marshal(obj)
		pipe.Set(ctx, objKey, data, 0)

		// Mettre Ã  jour la LRU si nÃ©cessaire
		if c.LRU != nil {
			c.LRU.MarkUsed(c.Name, id)
		}

		// Mettre Ã  jour les index
		for field := range c.Schema {
			if field == "id" {
				continue
			}
			// Supprimer l'ancien index si la valeur a changÃ©
			if oldVal, ok := obj[field]; ok {
				oldValStr := fmt.Sprintf("%v", oldVal)
				idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, oldValStr)
				pipe.SAdd(ctx, idxKey, id) // ajouter au nouvel index (SRem est dÃ©jÃ  gÃ©rÃ© dans Delete si on le souhaite)
			}
		}
	}

	_, err = pipe.Exec(ctx)
	if err != nil {
		log.Printf("Erreur execution pipeline Modify: %v", err)
		return err
	}

	return nil
}
```
Et elle s'utilise ainsi :
```go
// Modifier tous les messages de conversation 49 pour changer le state Ã  5
messages := NewCollection("messages", schemaMessages, rdb, lru)

filter := map[string]interface{}{
	"conversation_id": map[string]interface{}{"$eq": 49},
}

update := map[string]interface{}{
	"state": 5,
}

if err := cacheName.Modify(filter, update); err != nil {
	log.Println("Erreur modification:", err)
}
```
- CrÃ©ation de la fonction `InitCacheDatabase` qui consiste Ã  lancer la crÃ©ation des collections en cache redis. Cette fonction est utilisÃ© dÃ¨s le main. Les variables globale dont ensuite alimentÃ© pour etre le stockage des paramÃ¨tres de leur collection qui est associÃ©.
```go
// ---------------- Initialisation ----------------
// declarations globales
var (
	Users               *Collection
	UserSettings        *Collection
	Sessions            *Collection
	Relations           *Collection
	Posts               *Collection
	Comments            *Collection
	Likes               *Collection
	Media               *Collection
	ConversationsMeta   *Collection
	ConversationMembers *Collection
	Messages            *Collection
)

// InitCacheDatabase initialise la structure logique de Redis pour les caches
func InitCacheDatabase() {
	// Initialiser les collections

	schemaUsers := UsersSchema
	schemaUserSettings := UserSettingsSchema
	schemaSessions := SessionsSchema
	schemaRelations := RelationsSchema
	schemaPosts := PostsSchema
	schemaComments := CommentsSchema
	schemaLikes := LikesSchema
	schemaMedia := MediaSchema
	schemaConversationsMeta := ConversationsMetaSchema
	schemaConversationMembers := ConversationMembersSchema
	schemaMessages := MessagesSchema

	// variables globales
	Users = NewCollection("users", schemaUsers, Rdb, GlobalStrategy)
	UserSettings = NewCollection("user_settings", schemaUserSettings, Rdb, GlobalStrategy)
	Sessions = NewCollection("sessions", schemaSessions, Rdb, GlobalStrategy)
	Relations = NewCollection("relations", schemaRelations, Rdb, GlobalStrategy)
	Posts = NewCollection("posts", schemaPosts, Rdb, GlobalStrategy)
	Comments = NewCollection("comments", schemaComments, Rdb, GlobalStrategy)
	Likes = NewCollection("likes", schemaLikes, Rdb, GlobalStrategy)
	Media = NewCollection("media", schemaMedia, Rdb, GlobalStrategy)
	ConversationsMeta = NewCollection("conversations_meta", schemaConversationsMeta, Rdb, GlobalStrategy)
	ConversationMembers = NewCollection("conversation_members", schemaConversationMembers, Rdb, GlobalStrategy)
	Messages = NewCollection("messages", schemaMessages, Rdb, GlobalStrategy)

	log.Println("Structure Redis (caches) initialisÃ©e")
}}
```
3. `redis_stategy.go` :
Il y a eu Ã©galement une modification de la fonction `purgeOldest` afin de conformer Ã  la nouvelle forme de cache redis :
```go
func (lru *LRUCache) purgeOldest() {
	if lru.head == nil {
		return
	}
	old := lru.head
	log.Printf("Purging Redis cache element (LRU): node=%s, id=%s\n", old.NodeName, old.ElementID)
	lru.remove(old)
	delete(lru.elements, old.NodeName+":"+old.ElementID)

	// suppression via Collection.Delete
	collection := &Collection{
		Name:  old.NodeName,
		Redis: lru.rdb,
		LRU:   lru,
	}
	filter := map[string]interface{}{"id": old.ElementID}
	if err := collection.Delete(filter); err != nil {
		log.Printf("Erreur suppression via Collection.Delete: %v\n", err)
	}
}
```