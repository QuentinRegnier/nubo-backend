# NuboBackend
## ‚úÖ Objectif final

Un backend nomm√© `nubo-backend` avec :

- API REST (auth, CRUD de posts/messages, etc.)
- WebSocket (temps r√©el)
- Redis (cache/session)
- PostgreSQL (stockage permanent)
- MongoDB (stockage temporaire 30 jours)
- Docker (z√©ro installation locale, sauf Docker)

---

## üß± PR√âREQUIS (macOS)

Avant tout, installe :

- [Docker Desktop pour Mac](https://www.docker.com/products/docker-desktop/)
  - Ouvre-le une fois install√©
- Go (Golang) *(facultatif si tu build tout dans Docker, mais conseill√© pour dev local)*  
  `brew install go`
- Git *(souvent d√©j√† pr√©sent)*  
  `git --version`
- (Optionnel) Un bon √©diteur :
  - [VS Code](https://code.visualstudio.com/)
    - Extensions recommand√©es : **Go**, **Docker**, **GitLens**

---

## üóÇÔ∏è STRUCTURE DU PROJET

```
nubo-backend/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ go.mod
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ main.go
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ api/         ‚Üê Handlers REST
‚îÇ   ‚îú‚îÄ‚îÄ websocket/   ‚Üê Serveur WebSocket
‚îÇ   ‚îú‚îÄ‚îÄ db/          ‚Üê Connexion PostgreSQL & Mongo
‚îÇ   ‚îú‚îÄ‚îÄ cache/       ‚Üê Connexion Redis
‚îÇ   ‚îî‚îÄ‚îÄ models/      ‚Üê Structs & logique m√©tier
‚îî‚îÄ‚îÄ README.md
```

---

## I. üî® √âTAPES DE D√âVELOPPEMENT GO/DOCKER

### 1. Initialiser ton projet Go

```bash
mkdir nubo-backend && cd nubo-backend
go mod init github.com/tonuser/nubo-backend
```

> Remplace `tonuser` par ton pseudo GitHub

---

### 2. Cr√©er les fichiers essentiels

```bash
touch Dockerfile docker-compose.yml .env README.md
mkdir -p cmd internal/{api,websocket,db,cache,models}
touch cmd/main.go
```

---

### 3. Ajouter les d√©pendances Go

Installe les libs de base avec :

```bash
go get github.com/gin-gonic/gin              # REST API
go get github.com/go-redis/redis/v8          # Redis
go get go.mongodb.org/mongo-driver/mongo     # MongoDB
go get github.com/jackc/pgx/v5               # PostgreSQL
go get github.com/gorilla/websocket          # WebSocket
```

---

### 4. √âcrire ton `main.go`

```go
package main

import (
	"github.com/gin-gonic/gin"
)

func main() {
	r := gin.Default()

	r.GET("/ping", func(c *gin.Context) {
		c.JSON(200, gin.H{"message": "pong"})
	})

	r.Run(":8080")
}
```

---

### 5. Cr√©er le `Dockerfile`

```Dockerfile
FROM golang:1.24.5

WORKDIR /app

COPY go.mod ./
COPY go.sum ./
RUN go mod download

COPY . .

RUN go build -o nubo cmd/main.go

EXPOSE 8080

CMD ["./nubo"]
```

---

### 6. Cr√©er le `docker-compose.yml`

```yaml
services:
  api:
    build: .
    container_name: nubo_api
    ports:
      - "8080:8080"
    env_file:
      - .env
    depends_on:
      - redis
      - postgres
      - mongo
    restart: always

  redis:
    image: redis:7
    container_name: nubo_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  postgres:
    image: postgres:15
    container_name: nubo_postgres
    environment:
      POSTGRES_USER: nubo
      POSTGRES_PASSWORD: nubo
      POSTGRES_DB: nubo
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  mongo:
    image: mongo:7
    container_name: nubo_mongo
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

volumes:
  redis_data:
  postgres_data:
  mongo_data:
```

---

### 7. Lancer ton environnement

```bash
docker-compose up --build
```

Puis va sur [http://localhost:8080/ping](http://localhost:8080/ping) ‚Üí tu dois voir :

```json
{ "message": "pong" }
```

---

## II. üåê Cr√©ation du repo GitHub

- Cr√©er un repo vide (sur github.com) :
- Nom : nubo-backend
- Visibilit√© : Priv√© ou Public, √† toi de voir
- Puis en terminal :
```bash
git init
git remote add origin https://github.com/TON_USER/nubo-backend.git
git add .
git commit -m "Initial commit"
git branch -M main
git push -u origin main
```

---

## III. üõ†Ô∏è Plan d‚Äôaction clair (prochaine phase go)

‚úÖ √âtape 1 ‚Äî Ajouter les routes REST : Login, Signup, Post
‚úÖ √âtape 2 ‚Äî Ajouter le WebSocket en Go
‚úÖ √âtape 3 ‚Äî Brancher PostgreSQL, MongoDB, Redis
‚úÖ √âtape 4 ‚Äî Ajouter l‚Äôauthentification JWT
‚úÖ √âtape 5 ‚Äî D√©ployer sur un serveur Linux (Docker Compose + .env)
‚úÖ √âTAPE 1 ‚Äî Cr√©er les routes REST de base

---

### üéØ Objectif
**Cr√©er des routes :**

- `POST /signup` ‚Üí cr√©er un utilisateur
- `POST /login` ‚Üí connecter (renvoyer JWT, √† faire en √âtape 4)
- `GET /posts` ‚Üí r√©cup√©rer les posts
- `POST /posts` ‚Üí cr√©er un post

### üìÅ Organisation recommand√©e
Fichier : `internal/api/routes.go`
```go
package api

import (
	"github.com/gin-gonic/gin"
	"net/http"
)

func SetupRoutes(r *gin.Engine) {
	r.POST("/signup", SignUpHandler)
	r.POST("/login", LoginHandler)

	r.GET("/posts", GetPostsHandler)
	r.POST("/posts", CreatePostHandler)
}

func SignUpHandler(c *gin.Context) {
	// TODO: lire JSON, enregistrer utilisateur
	c.JSON(http.StatusOK, gin.H{"message": "signup ok"})
}

func LoginHandler(c *gin.Context) {
	// TODO: v√©rifier identifiants, renvoyer JWT
	c.JSON(http.StatusOK, gin.H{"message": "login ok"})
}

func GetPostsHandler(c *gin.Context) {
	// TODO: r√©cup√©rer les posts depuis la base
	c.JSON(http.StatusOK, gin.H{"posts": []string{"post 1", "post 2"}})
}

func CreatePostHandler(c *gin.Context) {
	// TODO: ajouter post √† la base
	c.JSON(http.StatusCreated, gin.H{"message": "post created"})
}
```

Ensuite, dans `cmd/main.go` :
```go
package main

import (
	"github.com/gin-gonic/gin"
	"github.com/QuentinRegnier/nubo-backend/internal/api"
)

func main() {
	r := gin.Default()
	api.SetupRoutes(r)
	r.Run(":8080")
}
```

Tu peux tester les endpoints avec curl ou Postman :
```bash
curl -X POST http://localhost:8080/signup
```
‚Üí tu dois voir :
```json
{"message":"signup ok"}
```

---

## IV. üöÄ √âtape WebSocket : cr√©er un serveur WebSocket basique en Go avec Gin + Gorilla WebSocket
### 1. Cr√©er un handler WebSocket

Fichier : `internal/websocket/handler.go`
```go
package websocket

import (
	"net/http"
	"github.com/gin-gonic/gin"
	"github.com/gorilla/websocket"
	"log"
)

// Configure le Upgrader (permet de passer du HTTP au WS)
var upgrader = websocket.Upgrader{
	CheckOrigin: func(r *http.Request) bool {
		// TODO : en prod, tu peux v√©rifier l'origine ici
		return true
	},
}

func WSHandler(c *gin.Context) {
	conn, err := upgrader.Upgrade(c.Writer, c.Request, nil)
	if err != nil {
		log.Println("Erreur d'upgrade websocket:", err)
		return
	}
	defer conn.Close()

	log.Println("Client connect√© via WebSocket")

	for {
		// Lecture message du client
		_, msg, err := conn.ReadMessage()
		if err != nil {
			log.Println("Erreur lecture message:", err)
			break
		}

		log.Printf("Message re√ßu: %s\n", msg)

		// Envoi d‚Äôun message de retour (√©cho)
		err = conn.WriteMessage(websocket.TextMessage, []byte("Echo: "+string(msg)))
		if err != nil {
			log.Println("Erreur √©criture message:", err)
			break
		}
	}
}
```

---

### 2. Brancher le WebSocket dans Gin

Dans `internal/api/routes.go`, ajoute :
```go
package api

import (
	"github.com/gin-gonic/gin"
	"github.com/QuentinRegnier/nubo-backend/internal/websocket"
)

func SetupRoutes(r *gin.Engine) {
	// Routes REST...
	r.POST("/signup", SignUpHandler)
	r.POST("/login", LoginHandler)
	r.GET("/posts", GetPostsHandler)
	r.POST("/posts", CreatePostHandler)

	// WebSocket
	r.GET("/ws", websocket.WSHandler)
}
```

---

### 3. Tester ton WebSocket localement
```bash
websocat ws://localhost:8080/ws
```
Tape un message, tu dois recevoir un `Echo: ton_message`.

---

### 4. √âtapes suivantes recommand√©es apr√®s ce test

- Ajouter un gestionnaire de connexions multiples (pool clients broadcast)
- Int√©grer Redis Pub/Sub pour scaler (via un canal central)
- Connecter le WebSocket √† la base (exemple : notifications)
- Prot√©ger le WS avec JWT (authentification)
- G√©rer la reconnexion automatique c√¥t√© client

---

### 5. Gestionnaire de connexions multiples + broadcast
### Objectif

Garder en m√©moire tous les clients connect√©s, pouvoir diffuser un message √† tous en m√™me temps (broadcast).

### 6. Code √† ajouter `internal/websocket/hub.go`
```go
package websocket

import (
	"log"
	"sync"

	"github.com/gorilla/websocket"
)

type Client struct {
	conn *websocket.Conn
	send chan []byte
}

type Hub struct {
	clients    map[*Client]bool
	broadcast  chan []byte
	register   chan *Client
	unregister chan *Client
	mu         sync.Mutex
}

func NewHub() *Hub {
	return &Hub{
		clients:    make(map[*Client]bool),
		broadcast:  make(chan []byte),
		register:   make(chan *Client),
		unregister: make(chan *Client),
	}
}

func (h *Hub) Run() {
	for {
		select {
		case client := <-h.register:
			h.mu.Lock()
			h.clients[client] = true
			h.mu.Unlock()
			log.Println("Client registered")

		case client := <-h.unregister:
			h.mu.Lock()
			if _, ok := h.clients[client]; ok {
				delete(h.clients, client)
				close(client.send)
				log.Println("Client unregistered")
			}
			h.mu.Unlock()

		case message := <-h.broadcast:
			h.mu.Lock()
			for client := range h.clients {
				select {
				case client.send <- message:
				default:
					close(client.send)
					delete(h.clients, client)
				}
			}
			h.mu.Unlock()
		}
	}
}

func (c *Client) ReadPump(hub *Hub) {
	defer func() {
		hub.unregister <- c
		c.conn.Close()
	}()
	for {
		_, msg, err := c.conn.ReadMessage()
		if err != nil {
			log.Println("Read error:", err)
			break
		}
		// On envoie le message re√ßu √† tout le monde
		hub.broadcast <- msg
	}
}

func (c *Client) WritePump() {
	for msg := range c.send {
		err := c.conn.WriteMessage(websocket.TextMessage, msg)
		if err != nil {
			log.Println("Write error:", err)
			break
		}
	}
	c.conn.Close()
}
```

### 7. Modifier le handler WebSocket `internal/websocket/handler.go`
```go
package websocket

import (
	"github.com/gin-gonic/gin"
	"github.com/gorilla/websocket"
	"log"
	"net/http"
)

var upgrader = websocket.Upgrader{
	CheckOrigin: func(r *http.Request) bool { return true },
}

var hub = NewHub()

func InitHub() {
	go hub.Run()
}

func WSHandler(c *gin.Context) {
	conn, err := upgrader.Upgrade(c.Writer, c.Request, nil)
	if err != nil {
		log.Println("Upgrade error:", err)
		return
	}

	client := &Client{
		conn: conn,
		send: make(chan []byte, 256),
	}

	hub.register <- client

	go client.WritePump()
	client.ReadPump(hub)
}
```

### Initialiser le hub dans `cmd/main.go`
```go
package main

import (
	"github.com/gin-gonic/gin"
	"nubo-backend/internal/api"
	"nubo-backend/internal/websocket"
)

func main() {
	r := gin.Default()

	websocket.InitHub()

	api.SetupRoutes(r)

	r.Run(":8080")
}
```

### 8. Test :
- Lance l‚ÄôAPI
- Connecte plusieurs clients au /ws
- Envoie un message d‚Äôun client ‚Üí Tous les clients re√ßoivent le message

---

## V. Int√©gration Redis Pub/Sub

Pourquoi ?

Pour permettre √† plusieurs instances de ton backend (scal√©es horizontalement) de communiquer, diffuser les messages WS entre elles.

### 1. Ajouter Redis Pub/Sub dans le hub

Installer Redis client d√©j√† fait avec `go-redis/redis/v8`

### 2. Ajouter un fichier `internal/cache/redis.go`
```go
package cache

import (
	"context"
	"os"

	"github.com/go-redis/redis/v8"
)

var Ctx = context.Background()
var Rdb *redis.Client

func InitRedis() {
	Rdb = redis.NewClient(&redis.Options{
		Addr:     os.Getenv("REDIS_ADDR"), // exemple : "localhost:6379"
		Password: "",                      // pas de mot de passe par d√©faut
		DB:       0,
	})
}
```

### 3. Modifie `cmd/main.go` pour initialiser Redis
```go
package main

import (
	"github.com/gin-gonic/gin"
	"nubo-backend/internal/api"
	"nubo-backend/internal/cache"
	"nubo-backend/internal/websocket"
	"log"
	"os"
)

func main() {
	// Initialiser Redis
	cache.InitRedis()

	// Initialiser Hub WS (modifi√© pour Redis)
	websocket.InitHub()

	r := gin.Default()
	api.SetupRoutes(r)

	port := os.Getenv("PORT")
	if port == "" {
		port = "8080"
	}
	log.Printf("Server listening on %s", port)
	r.Run(":" + port)
}
```

### 4. Modifier le hub pour utiliser Redis Pub/Sub

Dans `internal/websocket/hub.go` :

Ajoute en haut :
```go
import (
    "context"
    "log"
    "sync"

    "github.com/go-redis/redis/v8"
    "github.com/gorilla/websocket"
    "github.com/QuentinRegnier/nubo-backend/internal/cache"
)
```
Ajoute dans Hub :
```go
pubsub *redis.PubSub
channel string
Dans NewHub() :

h := &Hub{
	clients:    make(map[*Client]bool),
	broadcast:  make(chan []byte),
	register:   make(chan *Client),
	unregister: make(chan *Client),
	channel:    "nubo-websocket",
}
h.pubsub = cache.Rdb.Subscribe(context.Background(), h.channel)
go h.listenPubSub()
return h
```
Ajoute cette m√©thode :
```go
func (h *Hub) listenPubSub() {
	ch := h.pubsub.Channel()
	for msg := range ch {
		h.mu.Lock()
		for client := range h.clients {
			select {
			case client.send <- []byte(msg.Payload):
			default:
				close(client.send)
				delete(h.clients, client)
			}
		}
		h.mu.Unlock()
	}
}
```
Modifie la boucle case message := <-h.broadcast dans Run() :
```go
case message := <-h.broadcast:
	// Publie sur Redis
	err := cache.Rdb.Publish(context.Background(), h.channel, message).Err()
	if err != nil {
		log.Println("Redis publish error:", err)
	}
```

---

## VI. Connecter le WebSocket √† la base (exemple notifications)

### 1. Exemple rapide

Dans Client.ReadPump(), √† chaque message re√ßu, tu peux enregistrer ou traiter en DB.

### 2. Exemple dans `internal/websocket/hub.go` ReadPump :
```go
func (c *Client) ReadPump(hub *Hub) {
	defer func() {
		hub.unregister <- c
		c.conn.Close()
	}()
	for {
		_, msg, err := c.conn.ReadMessage()
		if err != nil {
			log.Println("Read error:", err)
			break
		}

		// TODO: sauvegarder msg en base (Postgres/Mongo)

		// Envoie le message aux autres clients
		hub.broadcast <- msg
	}
}
```

---

## VII. Prot√©ger le WS avec JWT

### 1. Ajouter middleware d‚Äôauthentification JWT
T√©l√©charger avant :
```bash
go get github.com/golang-jwt/jwt/v5
```

Dans `internal/api/middleware.go` :
```go
package api

import (
	"net/http"
	"strings"

	"github.com/gin-gonic/gin"
	"github.com/golang-jwt/jwt/v5"
)

var jwtSecret = []byte("ta-cle-secrete") // √† s√©curiser via .env

func JWTMiddleware() gin.HandlerFunc {
	return func(c *gin.Context) {
		authHeader := c.GetHeader("Authorization")
		if authHeader == "" {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Authorization header manquant"})
			return
		}

		tokenString := strings.TrimPrefix(authHeader, "Bearer ")
		token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) {
			return jwtSecret, nil
		})

		if err != nil || !token.Valid {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Token invalide"})
			return
		}

		claims, ok := token.Claims.(jwt.MapClaims)
		if !ok {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Claims invalides"})
			return
		}

		// Stocke l‚ÄôID utilisateur dans le contexte
		c.Set("userID", claims["sub"])

		c.Next()
	}
}
```

### 2. Prot√©ger la route WebSocket

Dans `internal/api/routes.go` :
```go
r.GET("/ws", JWTMiddleware(), websocket.WSHandler)
```
Dans `internal/websocket/handler.go`, r√©cup√©rer l‚ÄôID utilisateur (exemple)
```go
func WSHandler(c *gin.Context) {
	userID := c.GetString("userID")
	log.Println("Utilisateur connect√© (userID):", userID)

	// ‚Ä¶ reste inchang√©
}
```

---

### 3. ‚úÖ PR√âREQUIS AVANT DE TESTER

- Redis tourne bien (docker-compose up)
- Ton backend Go est lanc√© (go run cmd/main.go)
Tu as un JWT valide (car le WS est prot√©g√© maintenant) ‚Äî on en g√©n√®re un dans l'√©tape 1 üëá

---

### 4. üß™ G√©n√©rer un JWT de test

**Ajoute un petit endpoint temporaire dans internal/api/routes.go juste pour tester :**
```go
import "github.com/golang-jwt/jwt/v5"

func SetupRoutes(r *gin.Engine) {
	r.GET("/token", func(c *gin.Context) {
		token := jwt.NewWithClaims(jwt.SigningMethodHS256, jwt.MapClaims{
			"sub": "user123", // ID utilisateur
		})
		tokenString, _ := token.SignedString([]byte("ta-cle-secrete"))
		c.JSON(200, gin.H{"token": tokenString})
	})

	r.GET("/ws", JWTMiddleware(), websocket.WSHandler)
}
```

Lance ton API puis ex√©cute :
```bash
curl http://localhost:8080/token
```
Tu obtiens une r√©ponse comme :
```json
{"token":"eyJhbGciOiJIUzI1NiIsInR5cCI6Ikp..."}
```

---

### 5. üß™ Se connecter avec websocat + JWT

**Copie le token et lance cette commande dans le terminal :**
```bash
websocat ws://localhost:8081/ws -H 'Authorization: Bearer Remplace TON_JWT_ICI'
```
Remplace TON_JWT_ICI par le vrai token.

**‚úÖ Tu dois voir dans les logs :**
```bash
Utilisateur connect√© (userID): user123
Client registered
```

---

### 6. üß™ Tester le broadcast

- Ouvre deux terminaux avec cette m√™me commande websocat (et le m√™me token).
- Tape un message dans l‚Äôun. Tu dois le recevoir dans les deux.

**üí¨ Exemple :**
```bash
> Salut √† tous !
```

üü¢ Les deux clients doivent afficher Salut √† tous !.

---

### 7. üß™ Tester le Redis Pub/Sub (scalabilit√©)

**√âtapes :**
- Lance une deuxi√®me instance de ton backend (dans un autre terminal) :
```bash
go run cmd/main.go
```
- Connecte websocat √† chaque instance :
Instance 1 : port `8080`
Instance 2 : change √† la vol√©e : `r.Run(":8081")`, connecte √† `ws://localhost:8081/ws`
- Envoie un message sur une instance, il doit appara√Ætre sur toutes ‚Üí preuve que Redis propulse les messages entre les processus backend.

---

### 8. üß™ V√©rifie le JWT en cas d'erreur

Si tu connectes sans Authorization, tu dois recevoir :
```bash
{"error":"Authorization header manquant"}
```
Ou :
```bash
{"error":"Token invalide"}
```
## VIII. PostgreSQL & MongoDB
### 1. Mise en place de PostgreSQL avec pgAdmin
**Cr√©er la structure Docker pour PostgreSQL + pgAdmin**
Dans `docker-compose.yml`, ajoute la section PostgreSQL + pgAdmin :
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:16
    container_name: nubo_postgres
    environment:
      POSTGRES_USER: nubo_user
      POSTGRES_PASSWORD: nubo_password
      POSTGRES_DB: nubo_db
    ports:
      - "5432:5432"
    volumes:
      - ./postgres-data:/var/lib/postgresql/data

  pgadmin:
    image: dpage/pgadmin4
    container_name: nubo_pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@nubo.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "8082:80"
```
**D√©marre les services :**
`docker-compose -f docker-compose.yml up -d`
**R√©sultat attendu :**
PostgreSQL accessible sur `localhost:5432`
pgAdmin accessible sur http://localhost:8082
Tu peux connecter pgAdmin √† PostgreSQL avec nubo_user / nubo_password
**Cr√©er les dossiers pour les scripts SQL**
Arborescence sugg√©r√©e :
```bash
Nubo/
‚îú‚îÄ docker/
‚îÇ  ‚îî‚îÄ docker-compose.yml
‚îú‚îÄ sql/
‚îÇ  ‚îú‚îÄ init/       # Scripts de cr√©ation de tables de base
‚îÇ  ‚îú‚îÄ functions/  # Proc√©dures stock√©es, triggers
‚îÇ  ‚îî‚îÄ views/      # Vues SQL
```
Place tes fichiers `.sql` dans ces dossiers selon leur r√¥le.

---

### 2. Mise en place de MongoDB avec mongo-express
**Ajouter MongoDB √† Docker**
Toujours dans `docker-compose.yml`, ajoute :
```yaml
  mongo:
    image: mongo:7
    container_name: nubo_mongo
    ports:
      - "27017:27017"
    volumes:
      - ./mongo-data:/data/db

  mongo-express:
    image: mongo-express:1.0.0
    container_name: nubo_mongo_express
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: example
      ME_CONFIG_MONGODB_SERVER: mongo
    ports:
      - "8083:8081"
```
**D√©marre le service :**
`docker-compose -f docker-compose.yml up -d`
MongoDB accessible sur `localhost:27017`
mongo-express accessible sur http://localhost:8083
**Arborescence pour les scripts Mongo**
```bash
Nubo/
‚îú‚îÄ mongo/
‚îÇ  ‚îú‚îÄ init/          # Cr√©ation des collections, index, sharding
‚îÇ  ‚îú‚îÄ scripts/       # Inserts, indexes, TTL commands
‚îÇ  ‚îî‚îÄ workers/       # Workers pour traitement asynchrone
```

---

## IX. √âcriture dans les bases
### 1. R√®gle d‚Äôor (rappel rapide)
- **PostgreSQL** = syst√®me de v√©rit√©, int√©grit√©, contraintes, requ√™tes relationnelles (users, follow, param√®tres, archival √† vie).
- **MongoDB** = charge volatile/haut-volume, acc√®s par documents, donn√©es massives / flexibles / derni√®re p√©riode (cache, messages r√©cents, logs).
- Redis = stockage en m√©moire pour sessions / liste d‚Äôutilisateurs en ligne / counters / pubsub (d√©j√† en place).

### 2. Arborescence globale (haute niveau)
```bash
PostgreSQL
‚îú‚îÄ users
‚îÇ  ‚îú‚îÄ user_settings
‚îÇ  ‚îú‚îÄ sessions (refresh tokens / audit)
‚îú‚îÄ follows
‚îú‚îÄ blocks
‚îú‚îÄ posts
‚îÇ  ‚îú‚îÄ comments
‚îÇ  ‚îú‚îÄ likes
‚îú‚îÄ media (metadata minimal + pointer vers stockage objet)
‚îú‚îÄ conversations_meta
‚îÇ  ‚îú‚îÄ conversation_members
‚îÇ  ‚îú‚îÄ message_index (r√©sum√©/offset pour messages dans Mongo)
‚îú‚îÄ reports
‚îú‚îÄ admin_actions
‚îî‚îÄ audit_logs

MongoDB
‚îú‚îÄ messages                      (messages complets / growth)
‚îú‚îÄ posts_documents               (post + media metadata volumineux / versions)
‚îú‚îÄ comments_documents            (ou embedded in posts if small)
‚îú‚îÄ notifications                 (push & in-app notifications)
‚îú‚îÄ feed_cache                    (pr√©-calcul√©, TTL)
‚îú‚îÄ user_activity_logs            (clicks, views, events)
‚îú‚îÄ media_metadata                (vision/thumbnail/ai-tags)
‚îî‚îÄ search_index / embeddings     (opti. pour recommandations)
```

### 3. PostgreSQL : Tables clefs (sch√©ma r√©sum√©)

> Utiliser UUID (uuid_generate_v4()) pour tous les id en production. Datetime en timestamptz.

**PostgreSQL :**

**users**
- `id uuid PRIMARY KEY`
- `username text UNIQUE NOT NULL`
- `email text UNIQUE NOT NULL`
- `password_hash text NOT NULL`
- `salt text NULL` (si tu utilises scrypt/bcrypt, pas n√©cessaire)
- `display_name text`
- `bio text`
- `birthdate date`
- `phone text UNIQUE NULL`
- `profile_picture_id uuid NULL` (r√©f√©rence dans media)
- `state smallint NOT NULL DEFAULT 1` (1=active, 0=deleted, 2=banned)
- `created_at timestamptz DEFAULT now()`
- `updated_at timestamptz`
**Index** : `ON users (username)`, `ON users (email)`.
```sql
CREATE TABLE IF NOT EXISTS users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique de l'utilisateur
    username TEXT UNIQUE NOT NULL, -- nom d'utilisateur unique
    email TEXT UNIQUE NOT NULL, -- email unique
    email_verified BOOLEAN DEFAULT FALSE, -- email v√©rifi√©
    phone TEXT UNIQUE, -- num√©ro de t√©l√©phone unique
    phone_verified BOOLEAN DEFAULT FALSE, -- num√©ro de t√©l√©phone v√©rifi√©
    password_hash TEXT NOT NULL, -- mot de passe hach√©
    first_name TEXT NOT NULL, -- pr√©nom
    last_name TEXT NOT NULL, -- nom de famille
    birthdate DATE, -- date de naissance
    sex SMALLINT, -- sexe
    bio TEXT, -- biographie
    profile_picture_id UUID, -- id de l'image de profil
    grade SMALLINT NOT NULL DEFAULT 1, -- grade de l'utilisateur
    location TEXT, -- localisation de l'utilisateur
    school TEXT, -- √©cole
    works TEXT, -- emplois
    badges TEXT[], -- badges
    created_at TIMESTAMPTZ DEFAULT now(), -- date de cr√©ation
    updated_at TIMESTAMPTZ DEFAULT now() -- date de mise √† jour
);

CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
```

---

**user_settings**
- `id uuid PRIMARY KEY`
- `user_id uuid REFERENCES users(id) UNIQUE ON DELETE CASCADE`
- `privacy jsonb` (ex: {"posts":"public","messages":"friends"})
- `notifications jsonb` (per-type on/off)
- `language text`
- `theme text`
**Index** : `ON user_settings (user_id)`.
```sql
CREATE TABLE IF NOT EXISTS user_settings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique des param√®tres utilisateur
    user_id UUID UNIQUE REFERENCES users(id) ON DELETE CASCADE, -- id unique de l'utilisateur
    privacy JSONB, -- param√®tres de confidentialit√©
    notifications JSONB, -- param√®tres de notification
    language TEXT, -- langue
    theme SMALLINT NOT NULL DEFAULT 0 -- th√®me clair/sombre
);

CREATE INDEX idx_user_settings_user_id ON user_settings(user_id);
```
---

**sessions (refresh tokens / audit)**
- `id uuid PRIMARY KEY`
- `user_id uuid REFERENCES users(id)`
- `refresh_token text`
- `device_info jsonb`
- `ip inet`
- `created_at timestamptz`
- `expires_at timestamptz`
- `revoked boolean DEFAULT false`
**Index** : `ON sessions (user_id, revoked)`.
```sql
CREATE TABLE IF NOT EXISTS sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique de la session
    user_id UUID REFERENCES users(id), -- id de l'utilisateur
    refresh_token TEXT, -- token de rafra√Æchissement
    device_info JSONB, -- informations sur l'/les appareil(s)
    ip INET[], -- adresse IP
    created_at TIMESTAMPTZ DEFAULT now(), -- date de cr√©ation
    expires_at TIMESTAMPTZ, -- date d'expiration
    revoked BOOLEAN DEFAULT FALSE -- session r√©voqu√©e
);

CREATE INDEX idx_sessions_user_id_revoked ON sessions(user_id, revoked);
```
---

**follows**
- `id uuid PRIMARY KEY`
- `follower_id uuid REFERENCES users(id)`
- `followed_id uuid REFERENCES users(id)`
- `state smallint DEFAULT 1 (1=ok, 0=pending, 2=blocked)`
- `created_at timestamptz`
**Unique constraint** : `(follower_id, followed_id)`.
**Index** : `ON follows (followed_id)` pour feed queries.
```sql
CREATE TABLE IF NOT EXISTS follows (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du suivi
    followed_id UUID REFERENCES users(id), -- id de l'utilisateur suivi
    state SMALLINT DEFAULT 1, -- √©tat du suivi (2 = amis, 1 = suivi, 0 = inactif, -1 = bloqu√©)
    created_at TIMESTAMPTZ DEFAULT now(), -- date de cr√©ation
    UNIQUE(follower_id, followed_id)
);

CREATE INDEX idx_follows_followed_id ON follows(followed_id);
```
---

**posts**
- `id uuid PRIMARY KEY`
- `user_id uuid REFERENCES users(id) NOT NULL`
- `content text` (short textual content)
- `media_ids uuid[]` (pointeurs vers table media ou Mongo)
- `meta jsonb` (mentions, hashtags, extra props)
- `visibility smallint` (0=private,1=friends,2=public)
- `created_at timestamptz`
- `updated_at timestamptz`
**Index** : `ON posts (user_id, created_at DESC)` ; `GIN index ON posts (meta jsonb)` pour recherches.
```sql
CREATE TABLE IF NOT EXISTS posts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du post
    user_id UUID REFERENCES users(id) NOT NULL, -- id de l'utilisateur
    content TEXT, -- contenu du post
    media_ids UUID[], -- ids des m√©dias associ√©s
    meta JSONB, -- m√©tadonn√©es
    visibility SMALLINT DEFAULT 0, -- visibilit√© (1 = amis, 0 = public)
    location TEXT, -- localisation
    created_at TIMESTAMPTZ DEFAULT now(), -- date de cr√©ation
    updated_at TIMESTAMPTZ DEFAULT now() -- date de mise √† jour
);

CREATE INDEX idx_posts_user_created ON posts(user_id, created_at DESC);
CREATE INDEX idx_posts_meta ON posts USING GIN(meta);
```
---

**comments**
- `id uuid PRIMARY KEY`
- `post_id uuid REFERENCES posts(id) ON DELETE CASCADE`
- `user_id uuid REFERENCES users(id)`
- `content text`
- `created_at timestamptz`
**Index:** `ON comments (post_id, created_at DESC)`.
```sql
CREATE TABLE IF NOT EXISTS comments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du commentaire
    post_id UUID REFERENCES posts(id) ON DELETE CASCADE, -- id du post
    user_id UUID REFERENCES users(id), -- id de l'utilisateur
    content TEXT, -- contenu du commentaire
    created_at TIMESTAMPTZ DEFAULT now() -- date de cr√©ation
);

CREATE INDEX idx_comments_post_created ON comments(post_id, created_at DESC);
```
---

**likes**
- `id uuid PRIMARY KEY`
- `target_type text (post/comment)`
- `target_id uuid`
- `user_id uuid REFERENCES users(id)`
- `created_at timestamptz`
**Unique** `(target_type, target_id, user_id)`.
**Index** : `ON likes (target_type, target_id)`.
```sql
CREATE TABLE IF NOT EXISTS likes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du like
    target_type SMALLINT NOT NULL, -- type de la cible (0 = post, 1 = message, 2 = commentaire)
    target_id UUID NOT NULL, -- id de la cible
    user_id UUID REFERENCES users(id), -- id de l'utilisateur
    created_at TIMESTAMPTZ DEFAULT now(), -- date de cr√©ation
    UNIQUE(target_type, target_id, user_id)
);

CREATE INDEX idx_likes_target ON likes(target_type, target_id);
```
---

**conversations_meta**
- `id uuid PRIMARY KEY`
- `type smallint` (1=direct,2=group)
- `title text NULL`
- `last_message_text text NULL`
- `last_message_time timestamptz NULL`
- `created_at timestamptz`
**Index** : `ON conversations_meta (last_message_time DESC)`.
```sql
CREATE TABLE IF NOT EXISTS conversations_meta (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique de la conversation
    type SMALLINT, -- type de la conversation (0 = message priv√©e, 1 = groupe, 2 = communaut√©, 3 = annonce)
    title TEXT, -- titre de la conversation
    last_message_id UUID UNIQUE, -- id du dernier message
    state SMALLINT DEFAULT 0, -- √©tat de la conversation (0 = active, 1 = archiv√©e, 2 = supprim√©e)
    created_at TIMESTAMPTZ DEFAULT now() -- date de cr√©ation
);

CREATE INDEX idx_conversations_last_message ON conversations_meta(last_message_id);
```
---

**conversation_members**
- `id uuid PRIMARY KEY`
- `conversation_id uuid REFERENCES conversations_meta(id)`
- `user_id uuid REFERENCES users(id)`
- `role smallint` (admin/member)
- `joined_at timestamptz`
- `unread_count int DEFAULT 0`

**Unique** `(conversation_id, user_id)`.
```sql
CREATE TABLE IF NOT EXISTS conversation_members (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du membre
    conversation_id UUID REFERENCES conversations_meta(id), -- id de la conversation
    user_id UUID REFERENCES users(id), -- id de l'utilisateur
    role SMALLINT DEFAULT 0, -- r√¥le du membre (0 = membre, 1 = admin, 2 = cr√©ateur)
    joined_at TIMESTAMPTZ DEFAULT now(), -- date d'adh√©sion
    unread_count INT DEFAULT 0, -- nombre de messages non lus
    UNIQUE(conversation_id, user_id)
);
```
---

**message_index (r√©sum√© pour acc√®s rapide)**
- `id uuid PRIMARY KEY` (same as Mongo message id or index)
- `conversation_id uuid REFERENCES conversations_meta(id)`
- `message_id text` (id in Mongo or pointer)
- `sender_id uuid`
- `created_at timestamptz`
- `snippet text` (first X chars)
**Index**: `ON message_index (conversation_id, created_at DESC)`.
**Pattern** : on √©crit le message complet dans MongoDB (champ texte, medias), et on √©crit une ligne d‚Äôindex/minimale en Postgres (message_index) pour permettre recherche pagination rapide, jointures, quotas, unread counters, etc.
```sql
CREATE TABLE IF NOT EXISTS message_index (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du message
    conversation_id UUID REFERENCES conversations_meta(id), -- id de la conversation
    sender_id UUID NOT NULL, -- id de l'exp√©diteur
    message_type SMALLINT NOT NULL DEFAULT 0, -- 0=text, 1=image, 2=publication, 3=vocal, 4=vid√©o
    content TEXT, -- contenu du message
    attachments JSONB, -- pointeurs vers fichiers S3 / metadata
    created_at TIMESTAMPTZ DEFAULT now(), -- date de cr√©ation
);


CREATE INDEX idx_message_index_conv_created ON message_index(conversation_id, created_at DESC);
```
---

**media (minimum metadata)**
- `id uuid PRIMARY KEY`
- `owner_id uuid`
- `storage_path text` (S3 path)
- `mime text`
- `size bigint`
- `width int, height int`
- `created_at timestamptz`
- `processing_state smallint` (0=pending,1=done)
**Index** : `ON media (owner_id)`.
```sql
CREATE TABLE IF NOT EXISTS media (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du m√©dia
    owner_id UUID REFERENCES users(id), -- id du propri√©taire
    storage_path TEXT, -- chemin de stockage
    created_at TIMESTAMPTZ DEFAULT now(), -- date de cr√©ation
);

CREATE INDEX idx_media_owner ON media(owner_id);
CREATE INDEX idx_media_created ON media(created_at);
```
---

**reports**
```sql
CREATE TABLE IF NOT EXISTS reports (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(), -- id unique du rapport
    actor_id UUID REFERENCES users(id), -- id de l'utilisateur ayant signal√©
    target_type SMALLINT NOT NULL, -- type de la cible (user/post/comment/etc)
    target_id UUID NOT NULL, -- id de la cible
    reason TEXT, -- raison du signalement
    state SMALLINT DEFAULT 0, -- √©tat du rapport (0=pending, 1=reviewed, 2=resolved)
    created_at TIMESTAMPTZ DEFAULT now() -- date de cr√©ation
);

CREATE INDEX idx_reports_actor ON reports(actor_id);
CREATE INDEX idx_reports_created ON reports(created_at);
```

### 4. PosgreSQL : Sch√©ma
```bash
üìÇ database/
 ‚îú‚îÄ‚îÄ üìÇ schemas/
 ‚îÇ    ‚îú‚îÄ‚îÄ auth/          ‚Üí utilisateurs, sessions, relations
 ‚îÇ    ‚îú‚îÄ‚îÄ content/       ‚Üí posts, comments, likes, media
 ‚îÇ    ‚îú‚îÄ‚îÄ messaging/     ‚Üí conversations, messages
 ‚îÇ    ‚îú‚îÄ‚îÄ moderation/    ‚Üí reports
 ‚îÇ    ‚îú‚îÄ‚îÄ logic/         ‚Üí fonctions + proc√©dures
 ‚îÇ    ‚îú‚îÄ‚îÄ views/         ‚Üí vues mat√©rialis√©es ou non
```

---

### 5. MongoDB
> Principe : stocker documents volumineux, formats libres, TTL sur ce qui est √©ph√©m√®re.
**MongoExpress**
- Cr√©er une nouvelle base `nubo_recent`
**Terminal**
1. Mets ton Homebrew √† jour :
```bash
brew update
```
2. Installe mongosh :
```bash
brew install mongosh
```
3. V√©rifie que √ßa marche :
```bash
mongosh --version
```
**Se connecter √† ton serveur Mongo**
Une fois install√©, tu pourras te connecter √† ton serveur MongoDB (celui o√π Mongo Express est branch√©).
En g√©n√©ral, si c‚Äôest en local :
```bash
mongosh "mongodb://root:example@localhost:27017"
```
Tu choisis la base (si ce n‚Äôest pas encore fait) :
```javascript
use nubo_recent
```
Ensuite tu colles ton script complet :
(voir collection)
---

**messages (collection)**
```javascript
// ---------------------- USERS ----------------------
db.createCollection("users_recent");
db.users_recent.createIndex({ username: 1 }, { unique: true });
db.users_recent.createIndex({ email: 1 }, { unique: true });

// Exemple d‚Äôinsertion compl√®te pour users_recent
db.users_recent.insertOne({
    _id: UUID(),
    username: "",
    email: "",
    email_verified: false,
    phone: null,
    phone_verified: false,
    password_hash: "",
    first_name: "",
    last_name: "",
    birthdate: null,
    sex: null,
    bio: "",
    profile_picture_id: null,
    grade: 1,
    location: "",
    school: "",
    work: "",
    badges: [],
    created_at: new Date(),
    updated_at: new Date(),
    connected: false
});

// ---------------------- USER SETTINGS ----------------------
db.createCollection("user_settings_recent");
db.user_settings_recent.createIndex({ user_id: 1 }, { unique: true });

db.user_settings_recent.insertOne({
    _id: UUID(),
    user_id: UUID(),
    privacy: {},
    notifications: {},
    language: "",
    theme: 0,
    created_at: new Date(),
    updated_at: new Date()
});

// ---------------------- SESSIONS ----------------------
db.createCollection("sessions_recent");
db.sessions_recent.createIndex({ user_id: 1, revoked: 1 });

db.sessions_recent.insertOne({
    _id: UUID(),
    user_id: UUID(),
    refresh_token: "",
    device_info: {},
    ip: [],
    created_at: new Date(),
    expires_at: null,
    revoked: false
});

// ---------------------- RELATIONS ----------------------
db.createCollection("relations_recent");
db.relations_recent.createIndex({ primary_id: 1 });
db.relations_recent.createIndex({ secondary_id: 1 });
db.relations_recent.createIndex({ secondary_id: 1, primary_id: 1 }, { unique: true });

db.relations_recent.insertOne({
    _id: UUID(),
    primary_id: UUID(),
    secondary_id: UUID(),
    state: 1,
    created_at: new Date()
});

// ---------------------- POSTS ----------------------
db.createCollection("posts_recent");
db.posts_recent.createIndex({ user_id: 1, created_at: -1 });

db.posts_recent.insertOne({
    _id: UUID(),
    user_id: UUID(),
    content: "",
    media_ids: [],
    visibility: 0,
    location: "",
    created_at: new Date(),
    updated_at: new Date()
});

// ---------------------- COMMENTS ----------------------
db.createCollection("comments_recent");
db.comments_recent.createIndex({ post_id: 1, created_at: -1 });

db.comments_recent.insertOne({
    _id: UUID(),
    post_id: UUID(),
    user_id: UUID(),
    content: "",
    created_at: new Date()
});

// ---------------------- LIKES ----------------------
db.createCollection("likes_recent");
db.likes_recent.createIndex({ target_type: 1, target_id: 1 });
db.likes_recent.createIndex({ target_type: 1, target_id: 1, user_id: 1 }, { unique: true });

db.likes_recent.insertOne({
    _id: UUID(),
    target_type: 0,
    target_id: UUID(),
    user_id: UUID(),
    created_at: new Date()
});

// ---------------------- MEDIA ----------------------
db.createCollection("media_recent");
db.media_recent.createIndex({ owner_id: 1 });
db.media_recent.createIndex({ created_at: 1 });

db.media_recent.insertOne({
    _id: UUID(),
    owner_id: UUID(),
    storage_path: "",
    created_at: new Date()
});

// ---------------------- CONVERSATIONS META ----------------------
db.createCollection("conversations_recent");
db.conversations_recent.createIndex({ last_message_id: 1 });

db.conversations_recent.insertOne({
    _id: UUID(),
    type: 0,
    title: "",
    last_message_id: null,
    state: 0,
    created_at: new Date()
});

// ---------------------- CONVERSATION MEMBERS ----------------------
db.createCollection("conversation_members_recent");
db.conversation_members_recent.createIndex({ conversation_id: 1, user_id: 1 }, { unique: true });

db.conversation_members_recent.insertOne({
    _id: UUID(),
    conversation_id: UUID(),
    user_id: UUID(),
    role: 0,
    joined_at: new Date(),
    unread_count: 0
});

// ---------------------- MESSAGES ----------------------
db.createCollection("messages_recent");
db.messages_recent.createIndex({ conversation_id: 1, created_at: -1 });

db.messages_recent.insertOne({
    _id: UUID(),
    conversation_id: UUID(),
    sender_id: UUID(),
    message_type: 0,
    state: 0,
    content: "",
    attachments: {},
    created_at: new Date()
});

// ---------------------- FEED CACHE ----------------------
db.createCollection("feed_cache");
db.feed_cache.createIndex({ user_id: 1, created_at: -1 });

db.feed_cache.insertOne({
    _id: UUID(),
    user_id: UUID(),
    items: [],
    created_at: new Date()
});
```

---

## X. Strat√©gie de requ√™tes des donn√©es :

### 1. Strat√©gie MongoDB r√©ajust√©e
1. R√©pliquer uniquement les donn√©es ‚Äúinteractives‚Äù du dernier mois :
- Interactions = lecture, √©criture, modification, likes, commentaires, etc.
- MongoDB ne re√ßoit que ce sous-ensemble des tables concern√©es (`users`, `sessions`, `posts`, `comments`, `likes`, `media`, `messages`, `conversations_meta`, `conversation_members`, `relations`).
- On ne fait pas de r√©plication totale. C‚Äôest donc bien un filtrage c√¥t√© Go, pas PostgreSQL.
2. Feed pr√©-calcul√©
- Continu pour les utilisateurs connect√©s.
- Occasionnel pour les utilisateurs non connect√©s, selon la charge serveur.
3. D√©cision de r√©pliquer / stocker les donn√©es :
- Exclusivement c√¥t√© Go, qui conna√Æt la logique m√©tier et peut filtrer les donn√©es ‚Äúr√©centes ou actives‚Äù.
- PostgreSQL n‚Äôest utilis√© que comme source de v√©rit√© pour les donn√©es anciennes ou massives.
4. Lecture multi-couche :
```text
Go cherche un message/post :
-> Redis (cache ultra rapide)
-> Mongo (donn√©es r√©centes ou lourdes)
-> PostgreSQL (historique ou requ√™tes complexes)
```
- On peut sauter des √©tapes si on sait d√©j√† que la donn√©e est ancienne ou que le filtre limite √† moins d‚Äôun mois.
5. √âcriture / suppression :
- √âcriture triple : Redis + Mongo + PostgreSQL.
- Suppression / update : idem, pour garder la coh√©rence.

---

### 2. Optimisation de la fil d‚Äôattente et des √©critures massives
**PostgreSQL**
- Batch insertions : plut√¥t que d‚Äô√©crire 50‚ÄØ000 lignes une par une, grouper les inserts dans une seule requ√™te `INSERT ... VALUES (...), (...), (...)`.
- Transactions group√©es : encapsuler plusieurs op√©rations dans une seule transaction r√©duit les commits, ce qui acc√©l√®re les √©critures et limite la fragmentation.
- COPY : pour des gros volumes, `COPY FROM` est beaucoup plus rapide qu‚Äôun `INSERT` classique.
- Prepared statements : si on fait beaucoup d‚Äôinserts similaires, pr√©parer la requ√™te et l‚Äôex√©cuter en boucle r√©duit l‚Äôoverhead.
- Indexes : d√©sactiver temporairement certains indexes pendant un bulk insert massif puis les reconstruire peut √™tre plus rapide.
**MongoDB**
- insertMany : Mongo g√®re tr√®s bien les insertions en masse via `insertMany`.
- Ordered=false : permet de continuer l‚Äôinsertion m√™me si certains documents √©chouent, utile pour les tr√®s gros batchs.
- Bulk API : `bulkWrite` permet de combiner insert, update, delete dans une seule op√©ration, tr√®s efficace pour la r√©plication / traitement de flux.
- Sharding : si le dataset devient massif, sharder sur une cl√© qui r√©partit uniform√©ment la charge d‚Äô√©criture (ex : `conversation_id` pour messages).
- Write concern : ajuster le write concern (`w=1` pour rapide, `w=majority` pour s√ªr) selon le besoin.
**G√©n√©ral**
- Parallelisation c√¥t√© Go :
	- Regrouper les √©critures par type et table.
	- Faire plusieurs goroutines pour envoyer les batchs en parall√®le.
	- Redis est naturellement rapide pour des mises √† jour concurrentes.

---

### 3. Sch√©ma conceptuel clair du flux multi-couche
```pgsql
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ       Utilisateur     ‚îÇ
                        ‚îÇ   (Mobile / Web)      ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                                    ‚ñº
                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                           ‚îÇ       Go        ‚îÇ
                           ‚îÇ  Orchestrateur  ‚îÇ
                           ‚îÇ   logique m√©tier‚îÇ
                           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ                            ‚îÇ                            ‚îÇ
      ‚ñº                            ‚ñº                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Redis     ‚îÇ           ‚îÇ     MongoDB     ‚îÇ         ‚îÇ  PostgreSQL     ‚îÇ
‚îÇ  Cache rapide ‚îÇ           ‚îÇ Donn√©es r√©centes‚îÇ         ‚îÇ Source de v√©rit√©‚îÇ
‚îÇ  - unread     ‚îÇ           ‚îÇ < 1 mois /      ‚îÇ         ‚îÇ historique      ‚îÇ
‚îÇ    counters   ‚îÇ           ‚îÇ interactions    ‚îÇ         ‚îÇ - toutes tables ‚îÇ
‚îÇ  - sessions   ‚îÇ           ‚îÇ - messages      ‚îÇ         ‚îÇ - contraintes   ‚îÇ
‚îÇ  - pub/sub    ‚îÇ           ‚îÇ - posts volum.  ‚îÇ         ‚îÇ   d‚Äôint√©grit√©   ‚îÇ
‚îÇ  - feed cache ‚îÇ           ‚îÇ - conversations ‚îÇ         ‚îÇ - requ√™tes      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ   r√©centes      ‚îÇ         ‚îÇ   complexes     ‚îÇ
                            ‚îÇ - medias r√©cents‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                    ‚îÇ
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   Batch / Bulk insertions ‚îÇ
                       ‚îÇ   insertMany / COPY       ‚îÇ
                       ‚îÇ   Parallelisation Go      ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

**Explications du flux**
1. Utilisateur interagit ‚Üí envoie une requ√™te √† Go.
2. Go d√©cide :
	- Lire ‚Üí Redis ‚Üí MongoDB ‚Üí PostgreSQL si n√©cessaire.
	- √âcrire ‚Üí Redis + MongoDB + PostgreSQL.
	- Supprimer ‚Üí Redis + MongoDB + PostgreSQL.
3. MongoDB contient uniquement les donn√©es r√©centes ou utilis√©es activement (moins d‚Äôun mois, interactions r√©centes).
4. Redis sert pour :
	- compteur de messages non lus,
	- sessions actives,
	- pub/sub temps r√©el,
	- feed cache temporaire.
5. PostgreSQL reste la source de v√©rit√© compl√®te, historique, contraintes d‚Äôint√©grit√©, et requ√™tes complexes (rapports, exports, analytics).

---

**Optimisation / charge serveur**
- Go peut batcher les insertions :
	- Messages, posts, commentaires ‚Üí insertMany pour Mongo, COPY ou multi-row insert pour PostgreSQL.
- Feed pr√©-calcul√© :
	- Pour les utilisateurs connect√©s ‚Üí continu.
	- Pour les non-connect√©s ‚Üí seulement quand charge CPU/RAM le permet (heures creuses).
- Lecture / filtre :
	- Pr√©-filtrer par moins d‚Äôun mois ‚Üí MongoDB.
	- Si besoin historique ‚Üí PostgreSQL.

## XI. Travail sur Go
### 1. Initialisation de Redis et Mongo :
__**Objectif :**__
- Forcer √† la suppr√©sion toutes les lignes ayant √©t√© utilis√© il y a plus d'un mois dans les collections de MongoDB dans la base `nubo_recent`
- Nettoyer totalement Redis

**Cr√©ation de `init.go` et insertion de la directive dans `main.go`**
```go
package initdata

import (
    "context"
    "log"
    "time"

    "github.com/QuentinRegnier/nubo-backend/internal/cache"
    "github.com/QuentinRegnier/nubo-backend/internal/db"
    "go.mongodb.org/mongo-driver/bson"
)

func CleanMongo() {
    ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
    defer cancel()

    dbRecent := db.MongoClient.Database("nubo_recent")

    // R√©cup√®re toutes les collections de la DB
    collections, err := dbRecent.ListCollectionNames(ctx, bson.D{})
    if err != nil {
        log.Printf("‚ùå Erreur r√©cup√©ration collections Mongo: %v", err)
        return
    }

    // Date limite : 30 jours
    threshold := time.Now().AddDate(0, 0, -30)

    for _, collName := range collections {
        coll := dbRecent.Collection(collName)

        // Supprime les documents dont last_use < threshold
        filter := bson.M{
            "last_use": bson.M{
                "$lt": threshold,
            },
        }

        res, err := coll.DeleteMany(ctx, filter)
        if err != nil {
            log.Printf("‚ùå Erreur suppression dans %s: %v", collName, err)
            continue
        }

        log.Printf("üßπ Nettoyage Mongo [%s] ‚Üí %d documents supprim√©s", collName, res.DeletedCount)
    }
}

func CleanRedis() {
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()

    err := cache.Rdb.FlushDB(ctx).Err()
    if err != nil {
        log.Printf("‚ùå Erreur flush Redis: %v", err)
        return
    }
    log.Println("üßπ Redis vid√© avec succ√®s ‚úÖ")
}

func InitData() {
    log.Println("=== Initialisation: Nettoyage Mongo + Redis ===")
    CleanMongo()
    CleanRedis()
    log.Println("=== Initialisation termin√©e ‚úÖ ===")
}
```
```go
// Nettoyage au d√©marrage
    initdata.InitData()
```

---

### 2. S√©curisation par JWT 
- mise en place d'une expiration dans le token
- mise en place de la connexion du JWT_SCRET dans celui dans `.env`
```go 
package api

import (
	"fmt"
	"net/http"
	"os"
	"time"

	"github.com/gin-gonic/gin"
	"github.com/golang-jwt/jwt/v5"
)

func JWTMiddleware() gin.HandlerFunc {
	return func(c *gin.Context) {
		tokenString := c.GetHeader("Authorization")
		if tokenString == "" {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Authorization header manquant"})
			return
		}

		// Retirer "Bearer " si pr√©sent
		if len(tokenString) > 7 && tokenString[:7] == "Bearer " {
			tokenString = tokenString[7:]
		}

		keyFunc := func(token *jwt.Token) (interface{}, error) {
			if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {
				return nil, fmt.Errorf("algorithme JWT invalide")
			}
			return []byte(os.Getenv("JWT_SECRET")), nil
		}

		token, err := jwt.Parse(tokenString, keyFunc)
		if err != nil || !token.Valid {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Token invalide"})
			return
		}

		claims, ok := token.Claims.(jwt.MapClaims)
		if !ok || !token.Valid {
			c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Claims invalides"})
			return
		}

		// V√©rification expiration
		if exp, ok := claims["exp"].(float64); ok {
			if time.Now().After(time.Unix(int64(exp), 0)) {
				c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Token expir√©"})
				return
			}
		}

		// Mettre l‚ÄôID utilisateur dans le contexte
		c.Set("userID", claims["sub"])

		c.Next()
	}
}
```

---

### 3. Dynamisation de la gestion de la RAM pour REDIS et cr√©ation de type de noeud
- type **flux** : permet d'envoyer des donn√©es √† d'autre WS, dur√©e de vie des donn√©es 1s
- type **cache** : permet de stocker des donn√©es pour soulager MongoDB et PostgreSQL ainsi que pour augmenter la vitesse, dur√©e de vie des donn√©es infini ou presque
- gestion int√©lligente de la RAM avec une marge laiss√© vide √† ne pas d√©passer sinon le programme purge les donn√©es les moins utilis√© de REDIS, ce sont bien les donn√©es qui sont purger et pas les noeuds entier
```go
// internal/cache/strategy_redis.go
package cache

import (
	"context"
	"log"
	"runtime"
	"sync"
	"time"

	"github.com/go-redis/redis/v8"
)

// ---------------- Types ----------------

// Type d‚Äôun noeud Redis
type NodeType int

const (
	NodeFlux NodeType = iota
	NodeCache
)

// Un √©l√©ment dans la LRU globale
type CacheElement struct {
	NodeName  string // nom du noeud (ex: "messages")
	ElementID string // ex: "392"
	prev      *CacheElement
	next      *CacheElement
}

// LRU globale pour les √©l√©ments de type cache
type LRUCache struct {
	elements map[string]*CacheElement // cl√© = nodeName:elementID
	head     *CacheElement
	tail     *CacheElement
	mu       sync.Mutex
	rdb      *redis.Client
}

// ---------------- Initialisation ----------------

// NewLRUCache initialise un cache LRU global
func NewLRUCache(rdb *redis.Client) *LRUCache {
	return &LRUCache{
		elements: make(map[string]*CacheElement),
		rdb:      rdb,
	}
}

// ---------------- Gestion usage ----------------

// MarkUsed marque un √©l√©ment comme utilis√© (move to tail)
func (lru *LRUCache) MarkUsed(nodeName, elementID string) {
	lru.mu.Lock()
	defer lru.mu.Unlock()

	key := nodeName + ":" + elementID
	elem, exists := lru.elements[key]
	if exists {
		lru.moveToTail(elem)
		return
	}

	elem = &CacheElement{NodeName: nodeName, ElementID: elementID}
	lru.elements[key] = elem
	lru.append(elem)
}

func (lru *LRUCache) moveToTail(elem *CacheElement) {
	if elem == lru.tail {
		return
	}
	lru.remove(elem)
	lru.append(elem)
}

func (lru *LRUCache) append(elem *CacheElement) {
	if lru.tail != nil {
		lru.tail.next = elem
		elem.prev = lru.tail
		elem.next = nil
		lru.tail = elem
	} else {
		lru.head = elem
		lru.tail = elem
	}
}

func (lru *LRUCache) remove(elem *CacheElement) {
	if elem.prev != nil {
		elem.prev.next = elem.next
	} else {
		lru.head = elem.next
	}
	if elem.next != nil {
		elem.next.prev = elem.prev
	} else {
		lru.tail = elem.prev
	}
	elem.prev = nil
	elem.next = nil
}

func (lru *LRUCache) purgeOldest() {
	if lru.head == nil {
		return
	}
	old := lru.head
	log.Printf("Purging Redis cache element (LRU): node=%s, id=%s\n", old.NodeName, old.ElementID)
	lru.remove(old)
	delete(lru.elements, old.NodeName+":"+old.ElementID)

	// suppression dans Redis
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()
	key := "cache:" + old.NodeName
	if err := lru.rdb.HDel(ctx, key, old.ElementID).Err(); err != nil {
		log.Printf("Erreur suppression Redis: %v\n", err)
	}
}

// ---------------- M√©moire ----------------

// StartMemoryWatcher surveille la RAM
func (lru *LRUCache) StartMemoryWatcher(maxRAM uint64, marge uint64, interval time.Duration) {
	go func() {
		for {
			var m runtime.MemStats
			runtime.ReadMemStats(&m)
			used := m.Alloc
			if maxRAM == 0 {
				maxRAM = getTotalRAM()
			}
			if used > maxRAM-marge {
				log.Printf("RAM utilis√©e=%d, d√©passement seuil=%d, purge LRU...\n", used, maxRAM-marge)
				lru.mu.Lock()
				lru.purgeOldest()
				lru.mu.Unlock()
			}
			time.Sleep(interval)
		}
	}()
}

func getTotalRAM() uint64 {
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	return m.Sys
}

// ---------------- Flux ----------------

// DefaultFluxTTL est le temps de vie par d√©faut d'un message de flux
const DefaultFluxTTL = 1 * time.Second

// PushFluxWithTTL publie un message sur un flux et cr√©e un TTL individuel
func PushFluxWithTTL(rdb *redis.Client, nodeName string, messageID string, message []byte, ttl time.Duration) error {
	ctx := context.Background()

	// Stocke le message temporairement avec TTL individuel
	key := "fluxmsg:" + messageID
	if err := rdb.Set(ctx, key, message, ttl).Err(); err != nil {
		return err
	}

	// Publie sur le canal pour diffusion imm√©diate
	channel := "flux:" + nodeName
	if err := rdb.Publish(ctx, channel, messageID).Err(); err != nil {
		return err
	}

	return nil
}

// SubscribeFlux s'abonne √† un flux et renvoie les messages via un channel Go
func SubscribeFlux(rdb *redis.Client, nodeName string) (<-chan []byte, context.CancelFunc) {
	channel := "flux:" + nodeName
	ctx, cancel := context.WithCancel(context.Background())

	pubsub := rdb.Subscribe(ctx, channel)
	ch := make(chan []byte, 100) // buffer c√¥t√© Go

	go func() {
		defer pubsub.Close()
		for msg := range pubsub.Channel() {
			messageID := msg.Payload
			// R√©cup√®re le message stock√© temporairement
			data, err := rdb.Get(ctx, "fluxmsg:"+messageID).Bytes()
			if err == redis.Nil {
				continue // TTL d√©j√† expir√©
			} else if err != nil {
				log.Println("Erreur r√©cup√©ration flux message:", err)
				continue
			}
			ch <- data
		}
		close(ch)
	}()

	return ch, cancel
}

// ---------------- Cache ----------------

// SetCache ajoute un √©l√©ment au cache
func (lru *LRUCache) SetCache(ctx context.Context, nodeName, elementID string, value []byte) error {
	key := "cache:" + nodeName
	if err := lru.rdb.HSet(ctx, key, elementID, value).Err(); err != nil {
		return err
	}
	lru.MarkUsed(nodeName, elementID)
	return nil
}

// GetCache lit un √©l√©ment du cache
func (lru *LRUCache) GetCache(ctx context.Context, nodeName, elementID string) ([]byte, error) {
	key := "cache:" + nodeName
	val, err := lru.rdb.HGet(ctx, key, elementID).Bytes()
	if err == redis.Nil {
		return nil, nil
	}
	if err == nil {
		lru.MarkUsed(nodeName, elementID)
	}
	return val, err
}

// ---------------- Global ----------------

// GlobalStrategy est l‚Äôinstance globale de strat√©gie LRU utilis√©e par toute l‚Äôapp
var GlobalStrategy *LRUCache
```
et dapatation du nouveau syst√®me dans le `hub.go` :
```go 
package websocket

import (
	"crypto/rand"
	"encoding/hex"
	"log"
	"sync"

	"github.com/QuentinRegnier/nubo-backend/internal/cache"
	"github.com/gorilla/websocket"
)

// generateMessageID cr√©e un ID unique pour chaque message
func generateMessageID() string {
	b := make([]byte, 8) // 8 octets ‚Üí 16 caract√®res hex
	if _, err := rand.Read(b); err != nil {
		return "msg-fallback" // fallback si erreur improbable
	}
	return hex.EncodeToString(b)
}

// ---------------- Clients ----------------

type Client struct {
	conn *websocket.Conn
	send chan []byte
}

// ---------------- Hub ----------------

type Hub struct {
	clients    map[*Client]bool
	register   chan *Client
	unregister chan *Client
	broadcast  chan []byte
	mu         sync.Mutex

	channel string
}

// NewHub cr√©e un nouveau Hub et lance l'√©coute du flux Redis
func NewHub() *Hub {
	h := &Hub{
		clients:    make(map[*Client]bool),
		register:   make(chan *Client),
		unregister: make(chan *Client),
		broadcast:  make(chan []byte),
		channel:    "nubo-websocket",
	}

	// Utilise la fonction SubscribeFlux pour recevoir les messages
	go h.listenFlux()
	return h
}

// listenFlux s'abonne au flux Redis et distribue les messages aux clients
func (h *Hub) listenFlux() {
	ch, cancel := cache.SubscribeFlux(cache.Rdb, h.channel)
	defer cancel()

	for msg := range ch {
		h.mu.Lock()
		for client := range h.clients {
			select {
			case client.send <- msg:
			default:
				close(client.send)
				delete(h.clients, client)
			}
		}
		h.mu.Unlock()
	}
}

// Run d√©marre la boucle principale du hub pour g√©rer l'inscription/d√©sinscription et la diffusion
func (h *Hub) Run() {
	for {
		select {
		case client := <-h.register:
			h.mu.Lock()
			h.clients[client] = true
			h.mu.Unlock()
			log.Println("Client registered")

		case client := <-h.unregister:
			h.mu.Lock()
			if _, ok := h.clients[client]; ok {
				delete(h.clients, client)
				close(client.send)
				log.Println("Client unregistered")
			}
			h.mu.Unlock()

		case message := <-h.broadcast:
			// Publie le message sur le flux Redis avec TTL individuel (ex: 1s)
			messageID := generateMessageID() // fonction pour cr√©er un ID unique
			err := cache.PushFluxWithTTL(cache.Rdb, h.channel, messageID, message, cache.DefaultFluxTTL)
			if err != nil {
				log.Println("Erreur PushFluxWithTTL:", err)
			}
		}
	}
}

// ---------------- Clients WS ----------------

// ReadPump lit les messages d‚Äôun client et les envoie au hub
func (c *Client) ReadPump(hub *Hub) {
	defer func() {
		hub.unregister <- c
		c.conn.Close()
	}()

	for {
		_, msg, err := c.conn.ReadMessage()
		if err != nil {
			log.Println("Read error:", err)
			break
		}

		// TODO: sauvegarder msg en base (Postgres/Mongo)

		// Envoie le message aux autres clients via le hub
		hub.broadcast <- msg
	}
}

// WritePump envoie les messages du hub au client
func (c *Client) WritePump() {
	for msg := range c.send {
		err := c.conn.WriteMessage(websocket.TextMessage, msg)
		if err != nil {
			log.Println("Write error:", err)
			break
		}
	}
	c.conn.Close()
}
```
ajout √©galement de la d√©claration de l'observation de la RAM dans `main.go` :
```go
// ‚ö° Initialiser la strat√©gie Redis
<cache.GlobalStrategy = cache.NewLRUCache(cache.Rdb)

// ‚ö° D√©marrer le watcher m√©moire
// maxRAM = 0 => autod√©tection
// marge = 200 Mo de marge de s√©curit√©
// interval = toutes les 2 secondes
cache.GlobalStrategy.StartMemoryWatcher(0, 200*1024*1024, 2*time.Second)
```

---

### 4. Dupliquer le WS pour faire des test de REDIS plus simplement :
```yaml
api1:
  build: .
  container_name: nubo_api1
  ports:
    - "8080:8080"
  env_file:
    - .env
  depends_on:
    - redis
    - postgres
    - mongo
  restart: always

api2:
  build: .
  container_name: nubo_api2
  ports:
    - "8081:8080" # m√™me port interne, mais expos√© sur un port diff√©rent
  env_file:
    - .env
  depends_on:
    - redis
    - postgres
    - mongo
  restart: always
```

---

### 5.  G√©rer et nouvelle architechture des caches + cr√©ations des collections
1. `redis_collections.go` :
Cr√©ation d'un sh√©ma pour cahcun des base sql :
```go
// MessagesCache
var MessagesSchema = map[string]reflect.Kind{
	"id":              reflect.String,
	"conversation_id": reflect.String,
	"sender_id":       reflect.String,
	"message_type":    reflect.Int,
	"state":           reflect.Int,
	"content":         reflect.String,
	"attachments":     reflect.Map, // JSONB
	"created_at":      reflect.String,
}
```
2. `redis_caches.go` :
- Cr√©ation d'un syst√®me de collections qui servira √† partir des shemas √† valider la structure des donn√©es envoyer √† la fonction Set mais aussi int√©ragir avec la collections dans le canal cache de REDIS de cette collections.
```go
// ---------------- Collection et sch√©ma ----------------

type Collection struct {
	Name       string                  // ex: "messages"
	Schema     map[string]reflect.Kind // ex: {"id": reflect.Int, "content": reflect.String}
	Redis      *redis.Client
	LRU        *LRUCache     // pour mettre √† jour la LRU si cache
	Expiration time.Duration // TTL par d√©faut pour chaque √©l√©ment, facultatif
}

// NewCollection cr√©e une collection avec un sch√©ma et LRU optionnel
func NewCollection(name string, schema map[string]reflect.Kind, rdb *redis.Client, lru *LRUCache) *Collection {
	_, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	// Initialiser les indexs pour chaque champ du sch√©ma
	for field := range schema {
		if field == "id" {
			continue
		}
		// on ne cr√©e pas les valeurs ici (elles seront ajout√©es au fur et √† mesure)
		// mais on garde la structure logique
		log.Printf("Index initialis√© pour collection=%s, champ=%s", name, field)
	}

	return &Collection{
		Name:   name,
		Schema: schema,
		Redis:  rdb,
		LRU:    lru,
	}
}

// ---------------- Validation ----------------

func (c *Collection) validate(obj map[string]any) error {
	for field, kind := range c.Schema {
		val, ok := obj[field]
		if !ok {
			return fmt.Errorf("champ manquant: %s", field)
		}
		if reflect.TypeOf(val).Kind() != kind {
			return fmt.Errorf("champ %s doit √™tre de type %s", field, kind.String())
		}
	}
	return nil
}
```
- Cette fonction `NewCollection` introduit surtout une nouvelle fa√ßon de penser et d'organiser les donn√©es dans le cache :
Ancienne structure cache "messages":
```markdown
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Redis Cache         ‚îÇ
‚îÇ        messages (hash)      ‚îÇ
‚îÇ                             ‚îÇ
‚îÇ  id ‚Üí {full message object} ‚îÇ
‚îÇ  392 ‚Üí {id:392, content...} ‚îÇ
‚îÇ  77  ‚Üí {id:77, content...}  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
         Collection LRU
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ id usage  ‚îÇ
         ‚îÇ 392, 77   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Notes:
- Recherche par id uniquement.
- Pour trouver par conversation_id ou sender_id, il faut parcourir tous les objets.
- Peu d‚Äôindex ‚Üí lente recherche sur crit√®res.

-----------------------------------------------------

Nouvelle structure cache "messages":
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               Redis Cache         	  ‚îÇ                       ‚îÇ  Index Redis par champ   ‚îÇ
‚îÇ             messages (hash)             ‚îÇ                       ‚îÇ                          ‚îÇ
‚îÇ                                         ‚îÇ                       ‚îÇ state:3 ‚Üí {392}          ‚îÇ
‚îÇ  392 ‚Üí {id:392, conversation_id:49, ...}‚îÇ           +           ‚îÇ conv_id:49 ‚Üí {392, 77}   ‚îÇ
‚îÇ  77  ‚Üí {id:77, conversation_id:49, ...} ‚îÇ                       ‚îÇ conv_id:50 ‚Üí {283}       ‚îÇ
‚îÇ  283 ‚Üí {id:283, conversation_id:50, ...}‚îÇ                       ‚îÇ sender_id:462 ‚Üí {392}    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      
                      ‚îÇ
                      ‚ñº
               Collection LRU
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ id usage per node ‚îÇ
              ‚îÇ 392 ‚Üí tail        ‚îÇ
              ‚îÇ 77  ‚Üí middle      ‚îÇ
              ‚îÇ 283 ‚Üí head        ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Notes:
- Recherche rapide par n‚Äôimporte quel champ index√©.
- Les objets restent dans le hash principal, seul l‚Äôindex est consult√©.
- LRU g√®re la m√©moire en supprimant uniquement les √©l√©ments les moins utilis√©s.
- Plus scalable pour filtres complexes comme conversation_id, state, sender_id, etc.
```
- Cr√©ation de la m√©thode `Set` qui permet d'ajouter un √©l√©ment dans un collection √† condition qu'il respecte la structure de la collection √† laquelle il compte appartenir. De plus on ajoute cette √©l√©ment avec son Id dans la liste LRU d'usage des donn√©es de fa√ßon √† avoir un syst√®me de suppr√©ssion d'√©l√©ment dans redis coh√©rent et continue tous au long de nos interraction avec redis.
```go
// ---------------- Set ----------------

// Set ajoute un √©l√©ment dans la collection
func (c *Collection) Set(obj map[string]any) error {
	if err := c.validate(obj); err != nil {
		log.Println("Validation √©chou√©e:", err)
		return err
	}

	id := fmt.Sprintf("%v", obj["id"])
	objKey := "cache:" + c.Name + ":" + id

	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	// Sauvegarde compl√®te dans Redis Hash
	if err := c.Redis.HMSet(ctx, objKey, obj).Err(); err != nil {
		return err
	}

	// Mettre √† jour les indexs
	for field := range c.Schema {
		if field == "id" {
			continue
		}
		if val, ok := obj[field]; ok {
			valStr := fmt.Sprintf("%v", val)
			idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, valStr)
			if err := c.Redis.SAdd(ctx, idxKey, id).Err(); err != nil {
				log.Printf("Erreur mise √† jour index %s: %v", idxKey, err)
			}
		}
	}

	// Mise √† jour LRU
	if c.LRU != nil {
		c.LRU.MarkUsed(c.Name, id)
	}

	return nil
}
```
Et elle s'utilise ainsi :
```go
// Ajouter un message
messages := NewCollection("messages", schemaMessages, rdb, lru)

messages.Set(map[string]interface{}{
	"id": 382, "conversation_id": 49, "sender_id": 462,
	"message_type": 0, "state": 3, "content": "my message",
	"attachements": nil, "create_at": "12:34-10-03-2007",
})
```
- Cr√©ation de la m√©thode `Get` qui consite en la recherche d'un √©l√©ment dans la collection redis, tous l'ambition de cette fonction c'est qu'elle peut accepter un codage de filtre grace √† la fonction `matchFilter` qui nous permet de d√©crypter le codage qui se base sur un MongoDB-like afin de simplifier l'encodage. La fonction b√©n√©ficie aussi de la nouvelle structure du cache redis avec l'ajout d'index lui permettant de chercher baucoup plus vite les pr√©cieux id.
```go
// ---------------- Get ----------------

// Get retourne tous les √©l√©ments correspondant au filtre (MongoDB-like)
func (c *Collection) Get(filter map[string]any) ([]map[string]any, error) {
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	var candidateIDs []string

	// üîπ √âtape 1 : R√©duire l‚Äôespace de recherche avec les index Redis
	indexKeys := []string{}
	for field, condition := range filter {
		subCond, ok := condition.(map[string]any)
		if !ok {
			// √©quivalent $eq direct
			valStr := fmt.Sprintf("%v", condition)
			idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, valStr)
			indexKeys = append(indexKeys, idxKey)
			continue
		}

		for op, val := range subCond {
			switch op {
			case "$eq":
				valStr := fmt.Sprintf("%v", val)
				idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, valStr)
				indexKeys = append(indexKeys, idxKey)

			case "$in":
				arr, ok := val.([]any)
				if ok {
					orKeys := []string{}
					for _, a := range arr {
						valStr := fmt.Sprintf("%v", a)
						idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, valStr)
						orKeys = append(orKeys, idxKey)
					}
					// on mettra √ßa en union apr√®s
					if len(orKeys) > 0 {
						members, err := c.Redis.SUnion(ctx, orKeys...).Result()
						if err == nil {
							candidateIDs = append(candidateIDs, members...)
						}
					}
				}
			}
		}
	}

	// Si on a plusieurs indexKeys (issus de $eq), on fait une intersection
	if len(indexKeys) == 1 {
		ids, err := c.Redis.SMembers(ctx, indexKeys[0]).Result()
		if err == nil {
			candidateIDs = append(candidateIDs, ids...)
		}
	} else if len(indexKeys) > 1 {
		ids, err := c.Redis.SInter(ctx, indexKeys...).Result()
		if err == nil {
			candidateIDs = append(candidateIDs, ids...)
		}
	}

	// Si aucun index n‚Äôa filtr√© ‚Üí on doit scanner tout
	if len(candidateIDs) == 0 {
		pattern := fmt.Sprintf("cache:%s:*", c.Name)
		keys, scanErr := c.Redis.Keys(ctx, pattern).Result()
		if scanErr != nil {
			return nil, scanErr
		}
		for _, k := range keys {
			parts := strings.Split(k, ":")
			candidateIDs = append(candidateIDs, parts[len(parts)-1])
		}
	}

	// üîπ √âtape 2 : Charger les objets et appliquer matchFilter
	results := []map[string]any{}
	for _, id := range candidateIDs {
		objKey := "cache:" + c.Name + ":" + id
		data, err := c.Redis.HGetAll(ctx, objKey).Result()
		if err != nil || len(data) == 0 {
			continue
		}

		obj := make(map[string]any)
		for k, v := range data {
			obj[k] = v
		}

		// V√©rification compl√®te via matchFilter
		match, err := matchFilter(obj, filter)
		if err != nil {
			continue
		}
		if match {
			results = append(results, obj)
			if c.LRU != nil {
				c.LRU.MarkUsed(c.Name, id)
			}
		}
	}

	return results, nil
}
```
Et elle s'utilise ainsi :
```go
// Rechercher tous les √©l√©ments ayant conversation_id == 49
messages := NewCollection("messages", schemaMessages, rdb, lru)

// Rechercher
results, _ := messages.Get(map[string]interface{}{
	"conversation_id": map[string]interface{}{"$eq": 49},
})
```
- La fonction `matchFilter` a pour objectif de traduire une instruction de filtre json en un v√©ritable filtre utilisable dans la fonction `Get` et `Delete`.
Exemple :
```json
{
  "$and": [
    { "status": { "$eq": "active" } },               // √©gal √† "active"
    { "age": { "$gt": 18 } },                        // sup√©rieur √† 18
    { "score": { "$gte": 50 } },                     // sup√©rieur ou √©gal √† 50
    { "level": { "$lt": 10 } },                      // inf√©rieur √† 10
    { "rank": { "$lte": 5 } },                       // inf√©rieur ou √©gal √† 5
    { "category": { "$ne": "banned" } },            // diff√©rent de "banned"
    { "tags": { "$in": ["go", "json"] } },          // contient au moins "go" ou "json"
    { "priority": { "$nin": [0, 1] } },             // ne contient pas 0 ou 1
    { 
      "$or": [                                       // au moins une condition vraie
        { "vip": true },
        { "score": { "$gt": 90 } }
      ]
    },
    {
      "$not": { "region": { "$eq": "EU" } }         // region ‚â† EU
    },
    {
      "$nor": [                                      // aucune de ces conditions
        { "blocked": true },
        { "deleted": true }
      ]
    }
  ]
}
```
```go
// matchFilter applique le filtre type MongoDB sur un objet
func matchFilter(obj map[string]any, filter map[string]any) (bool, error) {
	for k, v := range filter {
		if strings.HasPrefix(k, "$") {
			switch k {
			case "$and":
				arr, ok := v.([]any)
				if !ok {
					return false, fmt.Errorf("$and doit √™tre un tableau")
				}
				for _, cond := range arr {
					subFilter, ok := cond.(map[string]any)
					if !ok {
						return false, fmt.Errorf("condition $and invalide")
					}
					match, err := matchFilter(obj, subFilter)
					if err != nil || !match {
						return false, err
					}
				}
				return true, nil
			case "$or":
				arr, ok := v.([]any)
				if !ok {
					return false, fmt.Errorf("$or doit √™tre un tableau")
				}
				for _, cond := range arr {
					subFilter, ok := cond.(map[string]any)
					if !ok {
						return false, fmt.Errorf("condition $or invalide")
					}
					match, err := matchFilter(obj, subFilter)
					if err == nil && match {
						return true, nil
					}
				}
				return false, nil
			case "$not":
				subFilter, ok := v.(map[string]any)
				if !ok {
					return false, fmt.Errorf("$not doit √™tre un objet")
				}
				match, err := matchFilter(obj, subFilter)
				return !match, err
			case "$nor":
				arr, ok := v.([]any)
				if !ok {
					return false, fmt.Errorf("$nor doit √™tre un tableau")
				}
				for _, cond := range arr {
					subFilter, ok := cond.(map[string]any)
					if !ok {
						return false, fmt.Errorf("condition $nor invalide")
					}
					match, err := matchFilter(obj, subFilter)
					if err == nil && match {
						return false, nil
					}
				}
				return true, nil
			}
		} else {
			// op√©rateurs de comparaison
			subCond, ok := v.(map[string]any)
			if !ok {
				// √©quivalent $eq par d√©faut
				if obj[k] != v {
					return false, nil
				}
				continue
			}
			for op, val := range subCond {
				switch op {
				case "$eq":
					if obj[k] != val {
						return false, nil
					}
				case "$ne":
					if obj[k] == val {
						return false, nil
					}
				case "$gt":
					if !compareNumbers(obj[k], val, ">") {
						return false, nil
					}
				case "$gte":
					if !compareNumbers(obj[k], val, ">=") {
						return false, nil
					}
				case "$lt":
					if !compareNumbers(obj[k], val, "<") {
						return false, nil
					}
				case "$lte":
					if !compareNumbers(obj[k], val, "<=") {
						return false, nil
					}
				case "$in":
					arr, ok := val.([]any)
					if !ok {
						return false, nil
					}
					found := false
					for _, a := range arr {
						if a == obj[k] {
							found = true
							break
						}
					}
					if !found {
						return false, nil
					}
				case "$nin":
					arr, ok := val.([]any)
					if !ok {
						return false, nil
					}
					for _, a := range arr {
						if a == obj[k] {
							return false, nil
						}
					}
				}
			}
		}
	}
	return true, nil
}
```
- Cr√©ation de la m√©thode `Delete` permettant de supprimer un √©l√©ment d'une collections redis, pour cela elle utilise la m√™me technologie de filtrage que dans `Get`. La fonction a un d√©fis qui est de supprimer √©galement toutes les occurences de l'id dans l'index.
```go
// Delete supprime les √©l√©ments correspondant au filtre et nettoie les index vides
func (c *Collection) Delete(filter map[string]any) error {
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	// R√©cup√©rer les objets via Get (filtrage complet)
	objs, err := c.Get(filter)
	if err != nil {
		return err
	}

	pipe := c.Redis.TxPipeline()
	// Stocker les paires idxKey -> id pour v√©rifier apr√®s
	type idxCheck struct {
		idxKey string
	}
	var checks []idxCheck

	for _, obj := range objs {
		id := fmt.Sprintf("%v", obj["id"])
		objKey := "cache:" + c.Name + ":" + id

		// Supprimer le hash principal
		pipe.Del(ctx, objKey)

		// Supprimer l‚ÄôID de tous les indexs
		for field := range c.Schema {
			if field == "id" {
				continue
			}
			if val, ok := obj[field]; ok {
				valStr := fmt.Sprintf("%v", val)
				idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, valStr)
				pipe.SRem(ctx, idxKey, id)
				checks = append(checks, idxCheck{idxKey: idxKey})
			}
		}

		// Nettoyer la LRU
		if c.LRU != nil {
			c.LRU.mu.Lock()
			delete(c.LRU.elements, c.Name+":"+id)
			c.LRU.mu.Unlock()
		}
	}

	// Ex√©cuter le pipeline
	if _, err := pipe.Exec(ctx); err != nil {
		log.Printf("Erreur ex√©cution pipeline delete: %v", err)
		return err
	}

	// V√©rifier et supprimer les index vides
	for _, chk := range checks {
		count, err := c.Redis.SCard(ctx, chk.idxKey).Result()
		if err != nil {
			log.Printf("Erreur lecture index %s: %v", chk.idxKey, err)
			continue
		}
		if count == 0 {
			if err := c.Redis.Del(ctx, chk.idxKey).Err(); err != nil {
				log.Printf("Erreur suppression index vide %s: %v", chk.idxKey, err)
			} else {
				log.Printf("Index vide supprim√©: %s", chk.idxKey)
			}
		}
	}

	return nil
}
```
Et elle s'utilise ainsi :
```go
// Supprimer tous les √©l√©ments ayant conversation_id == 49
messages := NewCollection("messages", schemaMessages, rdb, lru)

// Supprimer
messages.Delete(map[string]interface{}{
	"conversation_id": map[string]interface{}{"$eq": 49},
})
```
- Cr√©ation de la m√©thode `Modify` dans le m√™me style que `Delete` ou `Get` avec des filtres mais on ajoute √©galement un cat√©gorie update qui permet de pr√©ciser ce que l'on veut changer. Il ya aussi un gros enjeux sur les indexs avec cette fonctions car elle doit tous les actualisers. Comme elle doit actualiser aussi la liste LRU comme d'habitude.
```go
// Modify met √† jour les √©l√©ments correspondant au filtre avec les nouvelles valeurs fournies dans update
func (c *Collection) Modify(filter map[string]interface{}, update map[string]interface{}) error {
	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
	defer cancel()

	// R√©cup√©rer les objets correspondant au filtre
	objs, err := c.Get(filter)
	if err != nil {
		return err
	}

	pipe := c.Redis.TxPipeline()

	for _, obj := range objs {
		id := fmt.Sprintf("%v", obj["id"])
		objKey := "cache:" + c.Name + ":" + id

		// Mettre √† jour l'objet avec les nouvelles valeurs
		for field, val := range update {
			obj[field] = val
		}

		// S√©rialiser et stocker dans Redis
		data, _ := json.Marshal(obj)
		pipe.Set(ctx, objKey, data, 0)

		// Mettre √† jour la LRU si n√©cessaire
		if c.LRU != nil {
			c.LRU.MarkUsed(c.Name, id)
		}

		// Mettre √† jour les index
		for field := range c.Schema {
			if field == "id" {
				continue
			}
			// Supprimer l'ancien index si la valeur a chang√©
			if oldVal, ok := obj[field]; ok {
				oldValStr := fmt.Sprintf("%v", oldVal)
				idxKey := fmt.Sprintf("idx:%s:%s:%s", c.Name, field, oldValStr)
				pipe.SAdd(ctx, idxKey, id) // ajouter au nouvel index (SRem est d√©j√† g√©r√© dans Delete si on le souhaite)
			}
		}
	}

	_, err = pipe.Exec(ctx)
	if err != nil {
		log.Printf("Erreur execution pipeline Modify: %v", err)
		return err
	}

	return nil
}
```
Et elle s'utilise ainsi :
```go
// Modifier tous les messages de conversation 49 pour changer le state √† 5
messages := NewCollection("messages", schemaMessages, rdb, lru)

filter := map[string]interface{}{
	"conversation_id": map[string]interface{}{"$eq": 49},
}

update := map[string]interface{}{
	"state": 5,
}

if err := cacheName.Modify(filter, update); err != nil {
	log.Println("Erreur modification:", err)
}
```
- Cr√©ation de la fonction `InitCacheDatabase` qui consiste √† lancer la cr√©ation des collections en cache redis. Cette fonction est utilis√© d√®s le main. Les variables globale dont ensuite aliment√© pour etre le stockage des param√®tres de leur collection qui est associ√©.
```go
// ---------------- Initialisation ----------------
// declarations globales
var (
	Users               *Collection
	UserSettings        *Collection
	Sessions            *Collection
	Relations           *Collection
	Posts               *Collection
	Comments            *Collection
	Likes               *Collection
	Media               *Collection
	ConversationsMeta   *Collection
	ConversationMembers *Collection
	Messages            *Collection
)

// InitCacheDatabase initialise la structure logique de Redis pour les caches
func InitCacheDatabase() {
	// Initialiser les collections

	schemaUsers := UsersSchema
	schemaUserSettings := UserSettingsSchema
	schemaSessions := SessionsSchema
	schemaRelations := RelationsSchema
	schemaPosts := PostsSchema
	schemaComments := CommentsSchema
	schemaLikes := LikesSchema
	schemaMedia := MediaSchema
	schemaConversationsMeta := ConversationsMetaSchema
	schemaConversationMembers := ConversationMembersSchema
	schemaMessages := MessagesSchema

	// variables globales
	Users = NewCollection("users", schemaUsers, Rdb, GlobalStrategy)
	UserSettings = NewCollection("user_settings", schemaUserSettings, Rdb, GlobalStrategy)
	Sessions = NewCollection("sessions", schemaSessions, Rdb, GlobalStrategy)
	Relations = NewCollection("relations", schemaRelations, Rdb, GlobalStrategy)
	Posts = NewCollection("posts", schemaPosts, Rdb, GlobalStrategy)
	Comments = NewCollection("comments", schemaComments, Rdb, GlobalStrategy)
	Likes = NewCollection("likes", schemaLikes, Rdb, GlobalStrategy)
	Media = NewCollection("media", schemaMedia, Rdb, GlobalStrategy)
	ConversationsMeta = NewCollection("conversations_meta", schemaConversationsMeta, Rdb, GlobalStrategy)
	ConversationMembers = NewCollection("conversation_members", schemaConversationMembers, Rdb, GlobalStrategy)
	Messages = NewCollection("messages", schemaMessages, Rdb, GlobalStrategy)

	log.Println("Structure Redis (caches) initialis√©e")
}}
```
3. `redis_stategy.go` :
Il y a eu √©galement une modification de la fonction `purgeOldest` afin de conformer √† la nouvelle forme de cache redis :
```go
func (lru *LRUCache) purgeOldest() {
	if lru.head == nil {
		return
	}
	old := lru.head
	log.Printf("Purging Redis cache element (LRU): node=%s, id=%s\n", old.NodeName, old.ElementID)
	lru.remove(old)
	delete(lru.elements, old.NodeName+":"+old.ElementID)

	// suppression via Collection.Delete
	collection := &Collection{
		Name:  old.NodeName,
		Redis: lru.rdb,
		LRU:   lru,
	}
	filter := map[string]interface{}{"id": old.ElementID}
	if err := collection.Delete(filter); err != nil {
		log.Printf("Erreur suppression via Collection.Delete: %v\n", err)
	}
}
```